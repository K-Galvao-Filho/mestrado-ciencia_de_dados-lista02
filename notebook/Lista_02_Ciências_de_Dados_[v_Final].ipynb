{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "253a71b0",
      "metadata": {
        "id": "253a71b0"
      },
      "source": [
        "# üìö An√°lise de Rede de E-mails - Google Colab (Execu√ß√£o Autom√°tica)\n",
        "Lista de Exerc√≠cios 2 - Ci√™ncia de Dados\n",
        "Universidade Federal de Alagoas (UFAL)\n",
        "Aluno: Kleber Jos√© Araujo Galv√£o Filho"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50166a62",
      "metadata": {
        "id": "50166a62"
      },
      "source": [
        "## üîº Upload do Dataset\n",
        "carregue a base de dados \".txt.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e75190",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "03e75190",
        "outputId": "0dfb93ce-5770-4831-818b-a2aea76a8550"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7a6a3559-f5cf-4994-8149-d993e71a1085\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7a6a3559-f5cf-4994-8149-d993e71a1085\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving email-Eu-core-temporal.txt.gz to email-Eu-core-temporal.txt.gz\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bda79f",
      "metadata": {
        "id": "41bda79f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import gzip\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from networkx.algorithms.community import louvain_partitions\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "567ea5ba",
      "metadata": {
        "id": "567ea5ba"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import os\n",
        "\n",
        "def carregar_dados(caminho_arquivo_gz, caminho_saida_csv=\"email-Eu-core-temporal.csv\"):\n",
        "    \"\"\"\n",
        "    Descomprime o arquivo .gz, l√™ o arquivo de texto e converte para CSV.\n",
        "    Args:\n",
        "        caminho_arquivo_gz (str): Caminho para o arquivo .gz.\n",
        "        caminho_saida_csv (str): Caminho onde o CSV ser√° salvo.\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame com colunas 'origem', 'destino', 'timestamp'.\n",
        "    \"\"\"\n",
        "    if os.path.exists(caminho_saida_csv):\n",
        "        print(f\"Carregando CSV existente: {caminho_saida_csv}\")\n",
        "        dados = pd.read_csv(caminho_saida_csv)\n",
        "        return dados\n",
        "\n",
        "    try:\n",
        "        with gzip.open(caminho_arquivo_gz, 'rt') as arquivo:\n",
        "            dados = pd.read_csv(arquivo, sep='\\s+', names=['origem', 'destino', 'timestamp'], engine='python')\n",
        "        dados.to_csv(caminho_saida_csv, index=False)\n",
        "        print(f\"Dados convertidos e salvos como: {caminho_saida_csv}\")\n",
        "        print(f\"Dataset carregado com {len(dados)} arestas.\")\n",
        "        return dados\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: Arquivo {caminho_arquivo_gz} n√£o encontrado.\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar o arquivo: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b727eb5",
      "metadata": {
        "id": "3b727eb5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def exercicio_2(dados, tipo_layout=\"spring\"):\n",
        "    \"\"\"\n",
        "    Visualiza a rede social direcionada com diferentes layouts.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "        tipo_layout (str): Tipo de layout ('spring', 'kamada', 'circular').\n",
        "    \"\"\"\n",
        "    grafo = nx.DiGraph()\n",
        "    arestas = dados[['origem', 'destino']].values\n",
        "    grafo.add_edges_from(arestas)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    if tipo_layout == \"spring\":\n",
        "        posicao = nx.spring_layout(grafo, k=0.15, iterations=20)\n",
        "        nome_arquivo = os.path.join(\"figuras\", \"exercicio_02_rede_spring.png\")\n",
        "        titulo = \"Rede de E-mails Direcionada (Spring Layout)\"\n",
        "    elif tipo_layout == \"kamada\":\n",
        "        posicao = nx.kamada_kawai_layout(grafo)\n",
        "        nome_arquivo = os.path.join(\"figuras\", \"exercicio_02_rede_kamada.png\")\n",
        "        titulo = \"Rede de E-mails Direcionada (Kamada-Kawai Layout)\"\n",
        "    elif tipo_layout == \"circular\":\n",
        "        posicao = nx.circular_layout(grafo)\n",
        "        nome_arquivo = os.path.join(\"figuras\", \"exercicio_02_rede_circular.png\")\n",
        "        titulo = \"Rede de E-mails Direcionada (Circular Layout)\"\n",
        "    else:\n",
        "        print(\"Layout inv√°lido. Usando spring como padr√£o.\")\n",
        "        posicao = nx.spring_layout(grafo, k=0.15, iterations=20)\n",
        "        nome_arquivo = os.path.join(\"figuras\", \"exercicio_02_rede_spring.png\")\n",
        "        titulo = \"Rede de E-mails Direcionada (Spring Layout)\"\n",
        "\n",
        "    nx.draw(grafo, posicao, node_size=50, arrows=True, with_labels=False)\n",
        "    plt.title(titulo)\n",
        "    plt.savefig(nome_arquivo)\n",
        "    plt.close()\n",
        "    print(f\"Visualiza√ß√£o da rede salva como '{nome_arquivo}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff9dc6c6",
      "metadata": {
        "id": "ff9dc6c6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "def exercicio_3(dados):\n",
        "    \"\"\"\n",
        "    Calcula a m√©dia dos menores caminhos na rede direcionada e analisa conectividade e efici√™ncia.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "    Returns:\n",
        "        float: M√©dia dos menores caminhos (maior componente conexo ou grafo completo).\n",
        "    \"\"\"\n",
        "    # Usa grafo direcionado para refletir a rede de e-mails\n",
        "    grafo = nx.DiGraph()\n",
        "    arestas = dados[['origem', 'destino']].values\n",
        "    grafo.add_edges_from(arestas)\n",
        "\n",
        "    # Verifica se o grafo √© fortemente conectado (para DiGraph)\n",
        "    if nx.is_strongly_connected(grafo):\n",
        "        media_caminhos = nx.average_shortest_path_length(grafo)\n",
        "        print(f\"M√©dia dos menores caminhos (grafo completo): {media_caminhos:.4f}\")\n",
        "    else:\n",
        "        # Usa o maior componente fortemente conexo\n",
        "        maior_componente = max(nx.strongly_connected_components(grafo), key=len)\n",
        "        grafo_componente = grafo.subgraph(maior_componente).copy()\n",
        "        media_caminhos = nx.average_shortest_path_length(grafo_componente)\n",
        "        print(f\"M√©dia dos menores caminhos (maior componente fortemente conexo): {media_caminhos:.4f}\")\n",
        "\n",
        "    # Interpreta√ß√£o detalhada\n",
        "    print(\"\\nAn√°lise da conectividade e efici√™ncia:\")\n",
        "    if media_caminhos < 6:\n",
        "        print(f\"A m√©dia de {media_caminhos:.4f} indica alta conectividade (caracter√≠stica de mundo pequeno).\")\n",
        "        print(\"E-mails tendem a alcan√ßar destinat√°rios com poucos intermedi√°rios, sugerindo comunica√ß√£o eficiente.\")\n",
        "    else:\n",
        "        print(f\"A m√©dia de {media_caminhos:.4f} sugere conectividade moderada a baixa.\")\n",
        "        print(\"A comunica√ß√£o pode ser menos eficiente, exigindo mais intermedi√°rios para e-mails entre n√≥s distantes.\")\n",
        "    print(\"Em redes sociais, m√©dias abaixo de 6 s√£o comuns, como no conceito de 'seis graus de separa√ß√£o'.\")\n",
        "\n",
        "    return media_caminhos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d72921",
      "metadata": {
        "id": "e0d72921"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "def exercicio_4(dados):\n",
        "    \"\"\"\n",
        "    Calcula os top 5 n√≥s com base em diferentes m√©tricas de centralidade.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "        metrica (str): 'betweenness', 'degree', ou 'closeness'.\n",
        "    Returns:\n",
        "        list: Lista de tuplas (n√≥, valor) para os 5 principais n√≥s.\n",
        "    \"\"\"\n",
        "    grafo = nx.DiGraph()\n",
        "    arestas = dados[['origem', 'destino']].values\n",
        "    grafo.add_edges_from(arestas)\n",
        "\n",
        "    centralidade = nx.betweenness_centrality(grafo)\n",
        "    nome_metrica = \"centralidade de intermedia√ß√£o\"\n",
        "\n",
        "    top_5 = sorted(centralidade.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "    print(f\"Top 5 n√≥s por {nome_metrica}:\")\n",
        "    for no, valor in top_5:\n",
        "        print(f\"N√≥ {no}: {valor:.4f}\")\n",
        "        print(\"N√≥s com alta intermedia√ß√£o conectam grupos distintos.\")\n",
        "\n",
        "    print(\"\\nInterpreta√ß√£o no contexto da institui√ß√£o de pesquisa:\")\n",
        "    print(\"A centralidade de intermedia√ß√£o mede a frequ√™ncia com que um n√≥ aparece nos menores caminhos entre outros n√≥s na rede de e-mails.\")\n",
        "    print(\"N√≥s com alta centralidade s√£o cruciais para o fluxo de informa√ß√µes, funcionando como pontes entre diferentes grupos ou departamentos.\")\n",
        "    print(\"\\nPoss√≠veis pap√©is desses n√≥s incluem:\")\n",
        "    print(\"- **L√≠deres de pesquisa**: Conectam equipes interdisciplinares, promovendo colabora√ß√£o em projetos acad√™micos.\")\n",
        "    print(\"- **Administradores**: Coordenam comunica√ß√µes institucionais, como an√∫ncios ou decis√µes estrat√©gicas.\")\n",
        "    print(\"- **Sistemas centrais**: Servidores de e-mail ou newsletters que disseminam informa√ß√µes amplamente.\")\n",
        "    print(\"\\nEstrutura da rede de comunica√ß√£o:\")\n",
        "    print(\"A presen√ßa de n√≥s com alta centralidade sugere uma rede integrada, onde a colabora√ß√£o entre departamentos √© facilitada.\")\n",
        "    print(\"No entanto, a rede √© centralizada, dependendo de poucos n√≥s cr√≠ticos. Isso implica:\")\n",
        "    print(\"- **Efici√™ncia**: Informa√ß√µes fluem rapidamente atrav√©s desses n√≥s, agilizando a troca de conhecimento.\")\n",
        "    print(\"- **Vulnerabilidade**: A sobrecarga ou aus√™ncia desses n√≥s pode fragmentar a comunica√ß√£o, isolando grupos e dificultando a colabora√ß√£o.\")\n",
        "    print(\"\\nImplica√ß√µes:\")\n",
        "    print(\"Esses n√≥s s√£o pontos estrat√©gicos para a institui√ß√£o, mas tamb√©m pontos de risco. Estrat√©gias como descentralizar comunica√ß√µes ou criar redund√¢ncias podem mitigar depend√™ncias.\")\n",
        "\n",
        "    return top_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7edc7e7a",
      "metadata": {
        "id": "7edc7e7a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from networkx.algorithms.community import louvain_partitions\n",
        "\n",
        "def exercicio_5(dados):\n",
        "    \"\"\"\n",
        "    Detecta comunidades usando o algoritmo de Louvain do NetworkX e encontra o n√≥ principal por maior grau de entrada.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "    Returns:\n",
        "        dict: Dicion√°rio mapeando ID da comunidade para o n√≥ principal.\n",
        "    \"\"\"\n",
        "    # Cria o grafo direcionado\n",
        "    grafo = nx.DiGraph()\n",
        "    arestas = dados[['origem', 'destino']].values\n",
        "    grafo.add_edges_from(arestas)\n",
        "\n",
        "    # Converte para grafo n√£o direcionado para detec√ß√£o de comunidades\n",
        "    grafo_nao_direcionado = grafo.to_undirected()\n",
        "\n",
        "    # Usa louvain_partitions para detectar comunidades\n",
        "    particoes = louvain_partitions(grafo_nao_direcionado, seed=42)  # seed para reprodutibilidade\n",
        "\n",
        "    # Seleciona a primeira parti√ß√£o (ou a com maior modularidade, se necess√°rio)\n",
        "    particao = next(particoes)  # Pega a primeira parti√ß√£o\n",
        "\n",
        "    # Organiza n√≥s por comunidade\n",
        "    comunidades = {}\n",
        "    for id_comunidade, comunidade in enumerate(particao):\n",
        "        comunidades[id_comunidade] = list(comunidade)\n",
        "\n",
        "    # Encontra o n√≥ principal por maior grau de entrada em cada comunidade\n",
        "    nos_principais = {}\n",
        "    for id_comunidade, nos in comunidades.items():\n",
        "        graus = grafo.in_degree()\n",
        "        nome_criterio = \"maior grau de entrada\"\n",
        "        graus_comunidade = [(no, graus[no]) for no in nos if no in grafo.nodes()]\n",
        "        if graus_comunidade:  # Verifica se a comunidade n√£o est√° vazia\n",
        "            no_principal = max(graus_comunidade, key=lambda x: x[1])[0]\n",
        "            nos_principais[id_comunidade] = no_principal\n",
        "            print(f\"Comunidade {id_comunidade}: N√≥ {no_principal} com {nome_criterio}\")\n",
        "        else:\n",
        "            print(f\"Comunidade {id_comunidade}: Nenhuma aresta de entrada encontrada\")\n",
        "\n",
        "    print(f\"N√≥s selecionados por {nome_criterio} s√£o centrais em suas comunidades.\")\n",
        "    return nos_principais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "798b176d",
      "metadata": {
        "id": "798b176d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def exercicio_6(dados, nos_principais):\n",
        "    \"\"\"\n",
        "    Plota o n√∫mero de arestas de entrada ao longo de 803 dias para os n√≥s principais.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "        nos_principais (dict): N√≥s com maior grau de entrada por comunidade.\n",
        "    \"\"\"\n",
        "    dados['dia'] = dados['timestamp'] // (24 * 3600)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for id_comunidade, no in nos_principais.items():\n",
        "        arestas_no = dados[dados['destino'] == no]\n",
        "        contagem_diaria = arestas_no.groupby('dia').size()\n",
        "        contagem_diaria = contagem_diaria.reindex(range(803), fill_value=0)\n",
        "        plt.plot(contagem_diaria.index, contagem_diaria.values, label=f\"N√≥ {no} (Comunidade {id_comunidade})\")\n",
        "\n",
        "    plt.xlabel(\"Dia\")\n",
        "    plt.ylabel(\"N√∫mero de E-mails Recebidos\")\n",
        "    plt.title(\"E-mails Recebidos ao Longo do Tempo\")\n",
        "    plt.legend()\n",
        "    nome_arquivo = os.path.join(\"figuras\", \"exercicio_06_temporal.png\")\n",
        "    plt.savefig(nome_arquivo)\n",
        "    plt.close()\n",
        "    print(f\"Visualiza√ß√£o temporal salva como '{nome_arquivo}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c0bec9",
      "metadata": {
        "id": "d5c0bec9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "def exercicio_7(dados, nos_principais):\n",
        "    \"\"\"\n",
        "    Decomp√µe s√©ries temporais de dois n√≥s escolhidos aleatoriamente, compara tend√™ncia e sazonalidade,\n",
        "    e retorna os n√≥s para uso posterior.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede (origem, destino, timestamp).\n",
        "        nos_principais (dict): N√≥s com maior grau de entrada por comunidade.\n",
        "    Returns:\n",
        "        tuple: (no_a, no_b), IDs dos n√≥s selecionados.\n",
        "    \"\"\"\n",
        "    # Seleciona dois n√≥s aleatoriamente\n",
        "    random.seed(42)  # Para reprodutibilidade\n",
        "    try:\n",
        "        nos = random.sample(list(nos_principais.values()), k=2)\n",
        "    except ValueError as e:\n",
        "        print(f\"Erro ao selecionar n√≥s: {str(e)}. Usando n√≥s padr√£o ou repetidos.\")\n",
        "        nos = list(nos_principais.values())[:2]\n",
        "        if len(nos) < 2:\n",
        "            nos = [nos[0], nos[0]] if nos else [0, 0]\n",
        "\n",
        "    no_a, no_b = nos\n",
        "    print(f\"N√≥s selecionados: A={no_a}, B={no_b}\")\n",
        "\n",
        "    # Converte timestamps para dias\n",
        "    dados['dia'] = dados['timestamp'] // (24 * 3600)\n",
        "    max_dias = 803  # Per√≠odo total da rede (fixo para consist√™ncia)\n",
        "\n",
        "    def obter_serie_temporal(no):\n",
        "        \"\"\"Obt√©m a s√©rie temporal de arestas de entrada para um n√≥.\"\"\"\n",
        "        arestas_no = dados[dados['destino'] == no]\n",
        "        contagem_diaria = arestas_no.groupby('dia').size()\n",
        "        return contagem_diaria.reindex(range(max_dias), fill_value=0)\n",
        "\n",
        "    try:\n",
        "        # Obt√©m s√©ries temporais\n",
        "        serie_a = obter_serie_temporal(no_a)\n",
        "        serie_b = obter_serie_temporal(no_b)\n",
        "\n",
        "        # Decomposi√ß√£o: modelo aditivo, per√≠odo semanal\n",
        "        modelo = \"additive\"\n",
        "        periodo_sazonal = 7\n",
        "        decomp_a = seasonal_decompose(serie_a, model=modelo, period=periodo_sazonal, extrapolate_trend='freq')\n",
        "        decomp_b = seasonal_decompose(serie_b, model=modelo, period=periodo_sazonal, extrapolate_trend='freq')\n",
        "\n",
        "        # Gera visualiza√ß√µes\n",
        "        for no, decomp in [(no_a, decomp_a), (no_b, decomp_b)]:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.subplot(411)\n",
        "            plt.plot(decomp.observed, label='Observado')\n",
        "            plt.legend(loc='best')\n",
        "            plt.subplot(412)\n",
        "            plt.plot(decomp.trend, label='Tend√™ncia')\n",
        "            plt.legend(loc='best')\n",
        "            plt.subplot(413)\n",
        "            plt.plot(decomp.seasonal, label='Sazonalidade')\n",
        "            plt.legend(loc='best')\n",
        "            plt.subplot(414)\n",
        "            plt.plot(decomp.resid, label='Ru√≠do')\n",
        "            plt.legend(loc='best')\n",
        "            nome_arquivo = os.path.join(\"figuras\", f\"exercicio_07_no_{no}.png\")\n",
        "            plt.suptitle(f\"Decomposi√ß√£o da S√©rie Temporal - N√≥ {no} (Per√≠odo Semanal, Modelo Aditivo)\")\n",
        "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "            plt.savefig(nome_arquivo)\n",
        "            plt.close()\n",
        "            print(f\"Gr√°fico salvo como '{nome_arquivo}'.\")\n",
        "\n",
        "        # Compara tend√™ncias e sazonalidades\n",
        "        correlacao_tendencia = np.corrcoef(decomp_a.trend, decomp_b.trend)[0, 1]\n",
        "        correlacao_sazonalidade = np.corrcoef(decomp_a.seasonal, decomp_b.seasonal)[0, 1]\n",
        "        print(f\"\\nCorrela√ß√£o entre n√≥s A={no_a} e B={no_b}:\")\n",
        "        print(f\"  Tend√™ncia: {correlacao_tendencia:.4f}\")\n",
        "        print(f\"  Sazonalidade: {correlacao_sazonalidade:.4f}\")\n",
        "\n",
        "        # Conclus√µes interpretativas\n",
        "        print(\"\\nInterpreta√ß√£o no contexto da institui√ß√£o:\")\n",
        "        if abs(correlacao_tendencia) > 0.7:\n",
        "            print(f\"A alta correla√ß√£o de tend√™ncia ({correlacao_tendencia:.4f}) indica que A e B t√™m padr√µes de longo prazo semelhantes. Eles podem ser l√≠deres ou departamentos centrais com fluxos de e-mails sincronizados, como grupos de pesquisa colaborativos.\")\n",
        "        else:\n",
        "            print(f\"A baixa correla√ß√£o de tend√™ncia ({correlacao_tendencia:.4f}) sugere que A e B t√™m din√¢micas distintas. Eles podem representar √°reas diferentes, como administra√ß√£o e pesquisa, com demandas de comunica√ß√£o independentes.\")\n",
        "\n",
        "        if abs(correlacao_sazonalidade) > 0.7:\n",
        "            print(f\"A alta correla√ß√£o de sazonalidade ({correlacao_sazonalidade:.4f}) mostra que A e B seguem ciclos semanais similares, possivelmente devido a rotinas institucionais compartilhadas, como reuni√µes ou relat√≥rios.\")\n",
        "        else:\n",
        "            print(f\"A baixa correla√ß√£o de sazonalidade ({correlacao_sazonalidade:.4f}) indica ciclos distintos, talvez com um n√≥ ativo em dias √∫teis e outro com picos espor√°dicos, refletindo fun√ß√µes variadas.\")\n",
        "\n",
        "        print(\"Esses padr√µes sugerem estrat√©gias para otimizar a comunica√ß√£o, como sincronizar fluxos para n√≥s correlacionados ou diversificar canais para n√≥s independentes.\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Erro na an√°lise temporal: {str(e)}. N√£o foi poss√≠vel completar a decomposi√ß√£o.\")\n",
        "        return None, None\n",
        "\n",
        "    return no_a, no_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "907a7f07",
      "metadata": {
        "id": "907a7f07"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def exercicio_8(dados, no_a, no_b):\n",
        "    \"\"\"\n",
        "    Cria n√≥ C e redireciona aleatoriamente 25% das arestas de A e B para C.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "        no_a (int): N√≥ A selecionado no Exerc√≠cio 7.\n",
        "        no_b (int): N√≥ B selecionado no Exerc√≠cio 7.\n",
        "    Returns:\n",
        "        tuple: DataFrame modificado e ID do novo n√≥ C.\n",
        "    \"\"\"\n",
        "    print(f\"Usando n√≥s do Exerc√≠cio 7: A={no_a}, B={no_b}\")\n",
        "\n",
        "    # Cria o novo n√≥ C\n",
        "    novo_no = max(dados['origem'].max(), dados['destino'].max()) + 1\n",
        "    print(f\"Criando novo n√≥ C: {novo_no}\")\n",
        "\n",
        "    # Cria uma c√≥pia do DataFrame para modifica√ß√µes\n",
        "    dados_modificados = dados.copy()\n",
        "\n",
        "    def redirecionar_arestas(no):\n",
        "        \"\"\"Redireciona aleatoriamente 25% das arestas destinadas ao n√≥ para novo_no.\"\"\"\n",
        "        arestas_no = dados_modificados[dados_modificados['destino'] == no]\n",
        "        num_arestas = len(arestas_no)\n",
        "        num_redirecionar = int(0.25 * num_arestas)\n",
        "        if num_redirecionar == 0:\n",
        "            print(f\"Nenhuma aresta redirecionada para n√≥ {no} (menos de 4 arestas).\")\n",
        "            return\n",
        "\n",
        "        # Seleciona aleatoriamente 25% das arestas\n",
        "        indices = arestas_no.sample(n=num_redirecionar, random_state=42).index\n",
        "        dados_modificados.loc[indices, 'destino'] = novo_no\n",
        "        print(f\"Redirecionadas {num_redirecionar} arestas do n√≥ {no} por amostragem aleat√≥ria.\")\n",
        "\n",
        "    # Redireciona arestas para A e B\n",
        "    redirecionar_arestas(no_a)\n",
        "    redirecionar_arestas(no_b)\n",
        "\n",
        "    return dados_modificados, novo_no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e4ec9b",
      "metadata": {
        "id": "b3e4ec9b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def exercicio_9(dados_modificados, no_a, no_b, novo_no):\n",
        "    \"\"\"\n",
        "    Repete a decomposi√ß√£o das s√©ries temporais para os n√≥s A, B e C ap√≥s modifica√ß√£o, compara tend√™ncias e sazonalidades, e tira conclus√µes.\n",
        "    Args:\n",
        "        dados_modificados (pd.DataFrame): DataFrame com a rede modificada.\n",
        "        no_a (int): N√≥ A do Exerc√≠cio 7.\n",
        "        no_b (int): N√≥ B do Exerc√≠cio 7.\n",
        "        novo_no (int): ID do novo n√≥ C do Exerc√≠cio 8.\n",
        "    \"\"\"\n",
        "    nos = [no_a, no_b, novo_no]\n",
        "    print(f\"N√≥s analisados: A={no_a}, B={no_b}, C={novo_no}\")\n",
        "\n",
        "    # Converte timestamps para dias\n",
        "    dados_modificados['dia'] = dados_modificados['timestamp'] // (24 * 3600)\n",
        "\n",
        "    def obter_serie_temporal(no):\n",
        "        \"\"\"Obt√©m a s√©rie temporal de arestas de entrada para um n√≥.\"\"\"\n",
        "        arestas_no = dados_modificados[dados_modificados['destino'] == no]\n",
        "        contagem_diaria = arestas_no.groupby('dia').size()\n",
        "        return contagem_diaria.reindex(range(803), fill_value=0)\n",
        "\n",
        "    try:\n",
        "        # Configura√ß√£o fixa: modelo aditivo, per√≠odo 7 dias\n",
        "        modelo = \"additive\"\n",
        "        periodo = 7\n",
        "\n",
        "        # Decomp√µe as s√©ries temporais para A, B e C\n",
        "        series = {no: obter_serie_temporal(no) for no in nos}\n",
        "        decomps = {\n",
        "            no: seasonal_decompose(serie, model=modelo, period=periodo, extrapolate_trend='freq')\n",
        "            for no, serie in series.items()\n",
        "        }\n",
        "\n",
        "        # Gera visualiza√ß√µes para cada n√≥\n",
        "        for no in nos:\n",
        "            decomp = decomps[no]\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.subplot(411)\n",
        "            plt.plot(decomp.observed, label='Observado')\n",
        "            plt.legend()\n",
        "            plt.subplot(412)\n",
        "            plt.plot(decomp.trend, label='Tend√™ncia')\n",
        "            plt.legend()\n",
        "            plt.subplot(413)\n",
        "            plt.plot(decomp.seasonal, label='Sazonalidade')\n",
        "            plt.legend()\n",
        "            plt.subplot(414)\n",
        "            plt.plot(decomp.resid, label='Ru√≠do')\n",
        "            plt.legend()\n",
        "            nome_arquivo = os.path.join(\"figuras\", f\"exercicio_09_no_{no}_modificado.png\")\n",
        "            plt.suptitle(f\"Decomposi√ß√£o da S√©rie Temporal para N√≥ {no} (Modificado, Per√≠odo=7, Modelo=aditivo)\")\n",
        "            plt.savefig(nome_arquivo)\n",
        "            plt.close()\n",
        "            print(f\"Decomposi√ß√£o salva como '{nome_arquivo}'.\")\n",
        "\n",
        "        # Compara tend√™ncias e sazonalidades (A vs. B, A vs. C, B vs. C)\n",
        "        pares = [(\"A vs. B\", no_a, no_b), (\"A vs. C\", no_a, novo_no), (\"B vs. C\", no_b, novo_no)]\n",
        "        for nome_par, n1, n2 in pares:\n",
        "            correlacao_tendencia = np.corrcoef(decomps[n1].trend, decomps[n2].trend)[0, 1]\n",
        "            correlacao_sazonalidade = np.corrcoef(decomps[n1].seasonal, decomps[n2].seasonal)[0, 1]\n",
        "            print(f\"\\nCorrela√ß√µes para {nome_par}:\")\n",
        "            print(f\"  Tend√™ncia: {correlacao_tendencia:.4f}\")\n",
        "            print(f\"  Sazonalidade: {correlacao_sazonalidade:.4f}\")\n",
        "\n",
        "        # Conclus√µes interpretativas\n",
        "        print(\"\\nInterpreta√ß√£o dos resultados ap√≥s redirecionamento:\")\n",
        "        # A vs. B\n",
        "        correlacao_tendencia_ab = np.corrcoef(decomps[no_a].trend, decomps[no_b].trend)[0, 1]\n",
        "        correlacao_sazonalidade_ab = np.corrcoef(decomps[no_a].seasonal, decomps[no_b].seasonal)[0, 1]\n",
        "        if abs(correlacao_tendencia_ab) > 0.7:\n",
        "            print(f\"A alta correla√ß√£o da tend√™ncia entre A e B ({correlacao_tendencia_ab:.4f}) sugere que o redirecionamento para C n√£o alterou significativamente seus padr√µes de longo prazo. Eles continuam desempenhando pap√©is complementares.\")\n",
        "        else:\n",
        "            print(f\"A baixa correla√ß√£o da tend√™ncia entre A e B ({correlacao_tendencia_ab:.4f}) indica que o redirecionamento pode ter diferenciado ainda mais suas din√¢micas de longo prazo, talvez reduzindo interdepend√™ncias.\")\n",
        "\n",
        "        if abs(correlacao_sazonalidade_ab) > 0.7:\n",
        "            print(f\"A alta correla√ß√£o da sazonalidade entre A e B ({correlacao_sazonalidade_ab:.4f}) implica que os ciclos semanais permanecem sincronizados, apesar do redirecionamento para C.\")\n",
        "        else:\n",
        "            print(f\"A baixa correla√ß√£o da sazonalidade entre A e B ({correlacao_sazonalidade_ab:.4f}) sugere que o redirecionamento alterou os ciclos temporais, possivelmente redistribuindo picos de e-mails.\")\n",
        "\n",
        "        # Impacto em C\n",
        "        correlacao_tendencia_ac = np.corrcoef(decomps[no_a].trend, decomps[novo_no].trend)[0, 1]\n",
        "        correlacao_tendencia_bc = np.corrcoef(decomps[no_b].trend, decomps[novo_no].trend)[0, 1]\n",
        "        correlacao_sazonalidade_ac = np.corrcoef(decomps[no_a].seasonal, decomps[novo_no].seasonal)[0, 1]\n",
        "        correlacao_sazonalidade_bc = np.corrcoef(decomps[no_b].seasonal, decomps[novo_no].seasonal)[0, 1]\n",
        "\n",
        "        if abs(correlacao_tendencia_ac) > 0.7 or abs(correlacao_tendencia_bc) > 0.7:\n",
        "            print(f\"A tend√™ncia de C √© semelhante √† de A ({correlacao_tendencia_ac:.4f}) ou B ({correlacao_tendencia_bc:.4f}), indicando que C assumiu parte do papel de longo prazo de um dos n√≥s originais.\")\n",
        "        else:\n",
        "            print(f\"A tend√™ncia de C √© distinta de A ({correlacao_tendencia_ac:.4f}) e B ({correlacao_tendencia_bc:.4f}), sugerindo que C opera de forma independente em longo prazo.\")\n",
        "\n",
        "        if abs(correlacao_sazonalidade_ac) > 0.7 or abs(correlacao_sazonalidade_bc) > 0.7:\n",
        "            print(f\"A sazonalidade de C √© semelhante √† de A ({correlacao_sazonalidade_ac:.4f}) ou B ({correlacao_sazonalidade_bc:.4f}), mostrando que C herdou ciclos semanais de pelo menos um dos n√≥s.\")\n",
        "        else:\n",
        "            print(f\"A sazonalidade de C √© distinta de A ({correlacao_sazonalidade_ac:.4f}) e B ({correlacao_sazonalidade_bc:.4f}), indicando que C tem padr√µes c√≠clicos pr√≥prios.\")\n",
        "\n",
        "        print(\"O redirecionamento para C pode ter redistribu√≠do a carga de comunica√ß√£o, afetando estrat√©gias institucionais, como balanceamento de servidores ou fluxos de e-mails.\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Erro na decomposi√ß√£o: {str(e)}. N√£o foi poss√≠vel completar a an√°lise.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d617f2",
      "metadata": {
        "id": "e6d617f2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "def exercicio_10(dados, dados_modificados, no_a, no_b, novo_no, teste=\"t_test\"):\n",
        "    \"\"\"\n",
        "    Analisa mudan√ßas no fluxo de e-mails para A, B e C com testes estat√≠sticos.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame original.\n",
        "        dados_modificados (pd.DataFrame): DataFrame com a rede modificada.\n",
        "        no_a (int): N√≥ A do Exerc√≠cio 7.\n",
        "        no_b (int): N√≥ B do Exerc√≠cio 7.\n",
        "        novo_no (int): ID do novo n√≥ C do Exerc√≠cio 8.\n",
        "        teste (str): 't_test' ou 'mann_whitney'.\n",
        "    \"\"\"\n",
        "    print(f\"Analisando n√≥s: A={no_a}, B={no_b}, C={novo_no}\")\n",
        "\n",
        "    # Calcula grau de entrada total\n",
        "    grau_entrada_antes = dados.groupby('destino').size()\n",
        "    grau_entrada_depois = dados_modificados.groupby('destino').size()\n",
        "\n",
        "    def obter_grau_entrada(no):\n",
        "        return grau_entrada_antes.get(no, 0), grau_entrada_depois.get(no, 0)\n",
        "\n",
        "    grau_a_antes, grau_a_depois = obter_grau_entrada(no_a)\n",
        "    grau_b_antes, grau_b_depois = obter_grau_entrada(no_b)\n",
        "    grau_c_antes, grau_c_depois = obter_grau_entrada(novo_no)\n",
        "\n",
        "    print(f\"N√≥ A grau de entrada: Antes={grau_a_antes}, Depois={grau_a_depois}\")\n",
        "    print(f\"N√≥ B grau de entrada: Antes={grau_b_antes}, Depois={grau_b_depois}\")\n",
        "    print(f\"N√≥ C grau de entrada: Antes={grau_c_antes}, Depois={grau_c_depois}\")\n",
        "\n",
        "    # Verifica redu√ß√£o em A e B, aumento em C\n",
        "    reduziu_a = grau_a_depois < grau_a_antes\n",
        "    reduziu_b = grau_b_depois < grau_b_antes\n",
        "    aumentou_c = grau_c_depois > grau_c_antes\n",
        "    if reduziu_a and reduziu_b:\n",
        "        print(\"O fluxo de e-mails para A e B diminuiu ap√≥s introdu√ß√£o do n√≥ C.\")\n",
        "        if aumentou_c:\n",
        "            print(\"O n√≥ C absorveu parte do fluxo, como esperado.\")\n",
        "        else:\n",
        "            print(\"O n√≥ C n√£o registrou aumento correspondente, sugerindo poss√≠veis discrep√¢ncias.\")\n",
        "    else:\n",
        "        print(\"O fluxo de e-mails para A e/ou B n√£o diminuiu consistentemente.\")\n",
        "\n",
        "    # S√©ries temporais di√°rias\n",
        "    dados['dia'] = dados['timestamp'] // (24 * 3600)\n",
        "    dados_modificados['dia'] = dados_modificados['timestamp'] // (24 * 3600)\n",
        "\n",
        "    def obter_grau_entrada_diario(no, df):\n",
        "        arestas_no = df[df['destino'] == no]\n",
        "        return arestas_no.groupby('dia').size().reindex(range(803), fill_value=0)\n",
        "\n",
        "    # Gera s√©ries para A, B e C\n",
        "    nos = [(no_a, \"A\"), (no_b, \"B\"), (novo_no, \"C\")]\n",
        "    series = {\n",
        "        nome: {\n",
        "            \"antes\": obter_grau_entrada_diario(no, dados),\n",
        "            \"depois\": obter_grau_entrada_diario(no, dados_modificados)\n",
        "        }\n",
        "        for no, nome in nos\n",
        "    }\n",
        "\n",
        "    # Testes de hip√≥teses\n",
        "    alfa = 0.05\n",
        "    for no, nome in nos:\n",
        "        serie_antes = series[nome][\"antes\"]\n",
        "        serie_depois = series[nome][\"depois\"]\n",
        "        try:\n",
        "            if teste == \"t_test\":\n",
        "                estatistica, valor_p = stats.ttest_rel(serie_antes, serie_depois)\n",
        "                nome_teste = \"teste t pareado\"\n",
        "            elif teste == \"mann_whitney\":\n",
        "                estatistica, valor_p = stats.mannwhitneyu(serie_antes, serie_depois, alternative='two-sided')\n",
        "                nome_teste = \"teste de Mann-Whitney U\"\n",
        "            else:\n",
        "                print(\"Teste inv√°lido. Usando t_test.\")\n",
        "                estatistica, valor_p = stats.ttest_rel(serie_antes, serie_depois)\n",
        "                nome_teste = \"teste t pareado\"\n",
        "\n",
        "            print(f\"N√≥ {nome} ({no}) {nome_teste}: estat√≠stica={estatistica:.4f}, p-valor={valor_p:.4f}\")\n",
        "            if valor_p < alfa:\n",
        "                print(f\"Mudan√ßa significativa no fluxo de e-mails do n√≥ {nome} (p < {alfa}).\")\n",
        "            else:\n",
        "                print(f\"Sem mudan√ßa significativa no fluxo de e-mails do n√≥ {nome} (p >= {alfa}).\")\n",
        "\n",
        "        except ValueError as e:\n",
        "            print(f\"Erro no teste para n√≥ {nome}: {str(e)}. Pulando an√°lise estat√≠stica.\")\n",
        "\n",
        "    # Conclus√µes institucionais\n",
        "    print(\"\\nConclus√µes para a institui√ß√£o:\")\n",
        "    if reduziu_a and reduziu_b and aumentou_c:\n",
        "        print(\"O redirecionamento para o n√≥ C foi eficaz em reduzir a carga de e-mails em A e B, transferindo parte do fluxo para C. Isso pode aliviar servidores ou administradores sobrecarregados, melhorando a efici√™ncia da comunica√ß√£o.\")\n",
        "        if series[\"A\"][\"depois\"].mean() < series[\"A\"][\"antes\"].mean() and series[\"B\"][\"depois\"].mean() < series[\"B\"][\"antes\"].mean():\n",
        "            print(\"Testes confirmam redu√ß√£o significativa no fluxo di√°rio, sugerindo que C assumiu responsabilidades de comunica√ß√£o.\")\n",
        "        else:\n",
        "            print(\"Embora o fluxo total tenha diminu√≠do, os padr√µes di√°rios n√£o mudaram significativamente, indicando que a redu√ß√£o pode ser distribu√≠da irregularmente.\")\n",
        "    else:\n",
        "        print(\"O redirecionamento n√£o reduziu consistentemente o fluxo para A e B, ou C n√£o absorveu o fluxo esperado. Isso pode indicar que a interven√ß√£o n√£o foi suficiente para balancear a comunica√ß√£o.\")\n",
        "        print(\"Recomenda-se revisar a propor√ß√£o de redirecionamento (25%) ou considerar outros n√≥s para redistribui√ß√£o.\")\n",
        "\n",
        "    print(\"Esses resultados podem orientar ajustes na infraestrutura de e-mails, como adicionar mais n√≥s ou otimizar fluxos para evitar gargalos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc49eb7d",
      "metadata": {
        "id": "fc49eb7d"
      },
      "source": [
        "## üöÄ Execu√ß√£o Autom√°tica dos Exerc√≠cios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa118d82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa118d82",
        "outputId": "797645d4-6f5c-426c-bbec-2f44f18a5b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exerc√≠cio 1: Carregando dados...\n",
            "Dados convertidos e salvos como: email-Eu-core-temporal.csv\n",
            "Dataset carregado com 332334 arestas.\n",
            "\n",
            "Exerc√≠cio 2: Visualizando rede...\n",
            "Visualiza√ß√£o da rede salva como 'figuras/exercicio_02_rede_spring.png'.\n",
            "\n",
            "Exerc√≠cio 3: Analisando m√©dia dos menores caminhos...\n",
            "M√©dia dos menores caminhos (maior componente fortemente conexo): 2.5475\n",
            "\n",
            "An√°lise da conectividade e efici√™ncia:\n",
            "A m√©dia de 2.5475 indica alta conectividade (caracter√≠stica de mundo pequeno).\n",
            "E-mails tendem a alcan√ßar destinat√°rios com poucos intermedi√°rios, sugerindo comunica√ß√£o eficiente.\n",
            "Em redes sociais, m√©dias abaixo de 6 s√£o comuns, como no conceito de 'seis graus de separa√ß√£o'.\n",
            "\n",
            "Exerc√≠cio 4: Calculando centralidade de intermedia√ß√£o...\n",
            "Top 5 n√≥s por centralidade de intermedia√ß√£o:\n",
            "N√≥ 90: 0.0749\n",
            "N√≥s com alta intermedia√ß√£o conectam grupos distintos.\n",
            "N√≥ 951: 0.0389\n",
            "N√≥s com alta intermedia√ß√£o conectam grupos distintos.\n",
            "N√≥ 2: 0.0280\n",
            "N√≥s com alta intermedia√ß√£o conectam grupos distintos.\n",
            "N√≥ 120: 0.0255\n",
            "N√≥s com alta intermedia√ß√£o conectam grupos distintos.\n",
            "N√≥ 159: 0.0255\n",
            "N√≥s com alta intermedia√ß√£o conectam grupos distintos.\n",
            "\n",
            "Interpreta√ß√£o no contexto da institui√ß√£o de pesquisa:\n",
            "A centralidade de intermedia√ß√£o mede a frequ√™ncia com que um n√≥ aparece nos menores caminhos entre outros n√≥s na rede de e-mails.\n",
            "N√≥s com alta centralidade s√£o cruciais para o fluxo de informa√ß√µes, funcionando como pontes entre diferentes grupos ou departamentos.\n",
            "\n",
            "Poss√≠veis pap√©is desses n√≥s incluem:\n",
            "- **L√≠deres de pesquisa**: Conectam equipes interdisciplinares, promovendo colabora√ß√£o em projetos acad√™micos.\n",
            "- **Administradores**: Coordenam comunica√ß√µes institucionais, como an√∫ncios ou decis√µes estrat√©gicas.\n",
            "- **Sistemas centrais**: Servidores de e-mail ou newsletters que disseminam informa√ß√µes amplamente.\n",
            "\n",
            "Estrutura da rede de comunica√ß√£o:\n",
            "A presen√ßa de n√≥s com alta centralidade sugere uma rede integrada, onde a colabora√ß√£o entre departamentos √© facilitada.\n",
            "No entanto, a rede √© centralizada, dependendo de poucos n√≥s cr√≠ticos. Isso implica:\n",
            "- **Efici√™ncia**: Informa√ß√µes fluem rapidamente atrav√©s desses n√≥s, agilizando a troca de conhecimento.\n",
            "- **Vulnerabilidade**: A sobrecarga ou aus√™ncia desses n√≥s pode fragmentar a comunica√ß√£o, isolando grupos e dificultando a colabora√ß√£o.\n",
            "\n",
            "Implica√ß√µes:\n",
            "Esses n√≥s s√£o pontos estrat√©gicos para a institui√ß√£o, mas tamb√©m pontos de risco. Estrat√©gias como descentralizar comunica√ß√µes ou criar redund√¢ncias podem mitigar depend√™ncias.\n",
            "\n",
            "Exerc√≠cio 5: Detectando comunidades...\n",
            "Comunidade 0: N√≥ 534 com maior grau de entrada\n",
            "Comunidade 1: N√≥ 450 com maior grau de entrada\n",
            "Comunidade 2: N√≥ 383 com maior grau de entrada\n",
            "Comunidade 3: N√≥ 506 com maior grau de entrada\n",
            "Comunidade 4: N√≥ 897 com maior grau de entrada\n",
            "Comunidade 5: N√≥ 238 com maior grau de entrada\n",
            "Comunidade 6: N√≥ 629 com maior grau de entrada\n",
            "Comunidade 7: N√≥ 90 com maior grau de entrada\n",
            "Comunidade 8: N√≥ 742 com maior grau de entrada\n",
            "Comunidade 9: N√≥ 540 com maior grau de entrada\n",
            "Comunidade 10: N√≥ 115 com maior grau de entrada\n",
            "Comunidade 11: N√≥ 951 com maior grau de entrada\n",
            "Comunidade 12: N√≥ 577 com maior grau de entrada\n",
            "Comunidade 13: N√≥ 159 com maior grau de entrada\n",
            "Comunidade 14: N√≥ 61 com maior grau de entrada\n",
            "Comunidade 15: N√≥ 915 com maior grau de entrada\n",
            "Comunidade 16: N√≥ 2 com maior grau de entrada\n",
            "Comunidade 17: N√≥ 502 com maior grau de entrada\n",
            "N√≥s selecionados por maior grau de entrada s√£o centrais em suas comunidades.\n",
            "\n",
            "Exerc√≠cio 6: Visualizando comportamento temporal...\n",
            "Visualiza√ß√£o temporal salva como 'figuras/exercicio_06_temporal.png'.\n",
            "\n",
            "Exerc√≠cio 7: Decompondo s√©ries temporais...\n",
            "N√≥s selecionados: A=506, B=534\n",
            "Gr√°fico salvo como 'figuras/exercicio_07_no_506.png'.\n",
            "Gr√°fico salvo como 'figuras/exercicio_07_no_534.png'.\n",
            "\n",
            "Correla√ß√£o entre n√≥s A=506 e B=534:\n",
            "  Tend√™ncia: 0.6138\n",
            "  Sazonalidade: 0.9738\n",
            "\n",
            "Interpreta√ß√£o no contexto da institui√ß√£o:\n",
            "A baixa correla√ß√£o de tend√™ncia (0.6138) sugere que A e B t√™m din√¢micas distintas. Eles podem representar √°reas diferentes, como administra√ß√£o e pesquisa, com demandas de comunica√ß√£o independentes.\n",
            "A alta correla√ß√£o de sazonalidade (0.9738) mostra que A e B seguem ciclos semanais similares, possivelmente devido a rotinas institucionais compartilhadas, como reuni√µes ou relat√≥rios.\n",
            "Esses padr√µes sugerem estrat√©gias para otimizar a comunica√ß√£o, como sincronizar fluxos para n√≥s correlacionados ou diversificar canais para n√≥s independentes.\n",
            "\n",
            "Exerc√≠cio 8: Modificando a rede...\n",
            "Usando n√≥s do Exerc√≠cio 7: A=506, B=534\n",
            "Criando novo n√≥ C: 1005\n",
            "Redirecionadas 431 arestas do n√≥ 506 por amostragem aleat√≥ria.\n",
            "Redirecionadas 239 arestas do n√≥ 534 por amostragem aleat√≥ria.\n",
            "\n",
            "Exerc√≠cio 9: Decompondo s√©ries ap√≥s modifica√ß√£o...\n",
            "N√≥s analisados: A=506, B=534, C=1005\n",
            "Decomposi√ß√£o salva como 'figuras/exercicio_09_no_506_modificado.png'.\n",
            "Decomposi√ß√£o salva como 'figuras/exercicio_09_no_534_modificado.png'.\n",
            "Decomposi√ß√£o salva como 'figuras/exercicio_09_no_1005_modificado.png'.\n",
            "\n",
            "Correla√ß√µes para A vs. B:\n",
            "  Tend√™ncia: 0.5823\n",
            "  Sazonalidade: 0.9777\n",
            "\n",
            "Correla√ß√µes para A vs. C:\n",
            "  Tend√™ncia: 0.8172\n",
            "  Sazonalidade: 0.9602\n",
            "\n",
            "Correla√ß√µes para B vs. C:\n",
            "  Tend√™ncia: 0.7263\n",
            "  Sazonalidade: 0.9457\n",
            "\n",
            "Interpreta√ß√£o dos resultados ap√≥s redirecionamento:\n",
            "A baixa correla√ß√£o da tend√™ncia entre A e B (0.5823) indica que o redirecionamento pode ter diferenciado ainda mais suas din√¢micas de longo prazo, talvez reduzindo interdepend√™ncias.\n",
            "A alta correla√ß√£o da sazonalidade entre A e B (0.9777) implica que os ciclos semanais permanecem sincronizados, apesar do redirecionamento para C.\n",
            "A tend√™ncia de C √© semelhante √† de A (0.8172) ou B (0.7263), indicando que C assumiu parte do papel de longo prazo de um dos n√≥s originais.\n",
            "A sazonalidade de C √© semelhante √† de A (0.9602) ou B (0.9457), mostrando que C herdou ciclos semanais de pelo menos um dos n√≥s.\n",
            "O redirecionamento para C pode ter redistribu√≠do a carga de comunica√ß√£o, afetando estrat√©gias institucionais, como balanceamento de servidores ou fluxos de e-mails.\n",
            "\n",
            "Exerc√≠cio 10: Analisando impacto estat√≠stico da mudan√ßa...\n",
            "Analisando n√≥s: A=506, B=534, C=1005\n",
            "N√≥ A grau de entrada: Antes=1725, Depois=1294\n",
            "N√≥ B grau de entrada: Antes=959, Depois=720\n",
            "N√≥ C grau de entrada: Antes=0, Depois=670\n",
            "O fluxo de e-mails para A e B diminuiu ap√≥s introdu√ß√£o do n√≥ C.\n",
            "O n√≥ C absorveu parte do fluxo, como esperado.\n",
            "N√≥ A (506) teste t pareado: estat√≠stica=15.1002, p-valor=0.0000\n",
            "Mudan√ßa significativa no fluxo de e-mails do n√≥ A (p < 0.05).\n",
            "N√≥ B (534) teste t pareado: estat√≠stica=12.3529, p-valor=0.0000\n",
            "Mudan√ßa significativa no fluxo de e-mails do n√≥ B (p < 0.05).\n",
            "N√≥ C (1005) teste t pareado: estat√≠stica=-17.2371, p-valor=0.0000\n",
            "Mudan√ßa significativa no fluxo de e-mails do n√≥ C (p < 0.05).\n",
            "\n",
            "Conclus√µes para a institui√ß√£o:\n",
            "O redirecionamento para o n√≥ C foi eficaz em reduzir a carga de e-mails em A e B, transferindo parte do fluxo para C. Isso pode aliviar servidores ou administradores sobrecarregados, melhorando a efici√™ncia da comunica√ß√£o.\n",
            "Testes confirmam redu√ß√£o significativa no fluxo di√°rio, sugerindo que C assumiu responsabilidades de comunica√ß√£o.\n",
            "Esses resultados podem orientar ajustes na infraestrutura de e-mails, como adicionar mais n√≥s ou otimizar fluxos para evitar gargalos.\n"
          ]
        }
      ],
      "source": [
        "# Cria a pasta 'figuras' se n√£o existir\n",
        "os.makedirs(\"figuras\", exist_ok=True)\n",
        "\n",
        "# Exerc√≠cio 1 - Carregamento\n",
        "print(\"Exerc√≠cio 1: Carregando dados...\")\n",
        "dados = carregar_dados(\"email-Eu-core-temporal.txt.gz\")\n",
        "\n",
        "# Exerc√≠cio 2 - Visualiza√ß√£o\n",
        "print(\"\\nExerc√≠cio 2: Visualizando rede...\")\n",
        "exercicio_2(dados)\n",
        "\n",
        "# Exerc√≠cio 3 - An√°lise global\n",
        "print(\"\\nExerc√≠cio 3: Analisando m√©dia dos menores caminhos...\")\n",
        "exercicio_3(dados)\n",
        "\n",
        "# Exerc√≠cio 4 - An√°lise estrutural\n",
        "print(\"\\nExerc√≠cio 4: Calculando centralidade de intermedia√ß√£o...\")\n",
        "exercicio_4(dados)\n",
        "\n",
        "# Exerc√≠cio 5 - Comunidades\n",
        "print(\"\\nExerc√≠cio 5: Detectando comunidades...\")\n",
        "nos_principais = exercicio_5(dados)\n",
        "\n",
        "# Exerc√≠cio 6 - An√°lise temporal\n",
        "print(\"\\nExerc√≠cio 6: Visualizando comportamento temporal...\")\n",
        "exercicio_6(dados, nos_principais)\n",
        "\n",
        "# Exerc√≠cio 7 - S√©ries temporais\n",
        "print(\"\\nExerc√≠cio 7: Decompondo s√©ries temporais...\")\n",
        "no_a, no_b = exercicio_7(dados, nos_principais)\n",
        "\n",
        "# Exerc√≠cio 8 - Modifica√ß√£o da rede\n",
        "print(\"\\nExerc√≠cio 8: Modificando a rede...\")\n",
        "dados_modificados, novo_no = exercicio_8(dados, no_a, no_b)\n",
        "\n",
        "# Exerc√≠cio 9 - An√°lise da rede modificada\n",
        "print(\"\\nExerc√≠cio 9: Decompondo s√©ries ap√≥s modifica√ß√£o...\")\n",
        "exercicio_9(dados_modificados, no_a, no_b, novo_no)\n",
        "\n",
        "# Exerc√≠cio 10 - Teste de hip√≥teses\n",
        "print(\"\\nExerc√≠cio 10: Analisando impacto estat√≠stico da mudan√ßa...\")\n",
        "exercicio_10(dados, dados_modificados, no_a, no_b, novo_no, teste=\"t_test\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}