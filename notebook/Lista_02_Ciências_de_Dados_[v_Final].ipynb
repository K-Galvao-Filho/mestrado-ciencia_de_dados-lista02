{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "253a71b0",
      "metadata": {
        "id": "253a71b0"
      },
      "source": [
        "# ðŸ“š AnÃ¡lise de Rede de E-mails - Google Colab (ExecuÃ§Ã£o AutomÃ¡tica)\n",
        "Lista de ExercÃ­cios 2 - CiÃªncia de Dados\n",
        "Universidade Federal de Alagoas (UFAL)\n",
        "Aluno: Kleber JosÃ© Araujo GalvÃ£o Filho"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50166a62",
      "metadata": {
        "id": "50166a62"
      },
      "source": [
        "## ðŸ”¼ Upload do Dataset\n",
        "carregue a base de dados \".txt.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e75190",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "03e75190",
        "outputId": "0dfb93ce-5770-4831-818b-a2aea76a8550"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7a6a3559-f5cf-4994-8149-d993e71a1085\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7a6a3559-f5cf-4994-8149-d993e71a1085\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving email-Eu-core-temporal.txt.gz to email-Eu-core-temporal.txt.gz\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bda79f",
      "metadata": {
        "id": "41bda79f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import gzip\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from networkx.algorithms.community import louvain_partitions\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "567ea5ba",
      "metadata": {
        "id": "567ea5ba"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip\n",
        "import os\n",
        "\n",
        "def carregar_dados(caminho_arquivo_gz, caminho_saida_csv=\"email-Eu-core-temporal.csv\"):\n",
        "    \"\"\"\n",
        "    Descomprime o arquivo .gz, lÃª o arquivo de texto e converte para CSV.\n",
        "    Args:\n",
        "        caminho_arquivo_gz (str): Caminho para o arquivo .gz.\n",
        "        caminho_saida_csv (str): Caminho onde o CSV serÃ¡ salvo.\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame com colunas 'origem', 'destino', 'timestamp'.\n",
        "    \"\"\"\n",
        "    if os.path.exists(caminho_saida_csv):\n",
        "        print(f\"Carregando CSV existente: {caminho_saida_csv}\")\n",
        "        dados = pd.read_csv(caminho_saida_csv)\n",
        "        return dados\n",
        "\n",
        "    try:\n",
        "        with gzip.open(caminho_arquivo_gz, 'rt') as arquivo:\n",
        "            dados = pd.read_csv(arquivo, sep='\\s+', names=['origem', 'destino', 'timestamp'], engine='python')\n",
        "        dados.to_csv(caminho_saida_csv, index=False)\n",
        "        print(f\"Dados convertidos e salvos como: {caminho_saida_csv}\")\n",
        "        print(f\"Dataset carregado com {len(dados)} arestas.\")\n",
        "        return dados\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Erro: Arquivo {caminho_arquivo_gz} nÃ£o encontrado.\")\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar o arquivo: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b727eb5",
      "metadata": {
        "id": "3b727eb5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def exercicio_2(dados, tipo_layout=\"spring\"):\n",
        "    \"\"\"\n",
        "    Visualiza a rede social direcionada com diferentes layouts.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "        tipo_layout (str): Tipo de layout ('spring', 'kamada', 'circular').\n",
        "    \"\"\"\n",
        "    grafo = nx.DiGraph()\n",
        "    arestas = dados[['origem', 'destino']].values\n",
        "    grafo.add_edges_from(arestas)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    if tipo_layout == \"spring\":\n",
        "        posicao = nx.spring_layout(grafo, k=0.15, iterations=20)\n",
        "        nome_arquivo = os.path.join(\"figuras\", \"exercicio_02_rede_spring.png\")\n",
        "        titulo = \"Rede de E-mails Direcionada (Spring Layout)\"\n",
        "    elif tipo_layout == \"kamada\":\n",
        "        posicao = nx.kamada_kawai_layout(grafo)\n",
        "        nome_arquivo = os.path.join(\"figuras\", \"exercicio_02_rede_kamada.png\")\n",
        "        titulo = \"Rede de E-mails Direcionada (Kamada-Kawai Layout)\"\n",
        "    elif tipo_layout == \"circular\":\n",
        "        posicao = nx.circular_layout(grafo)\n",
        "        nome_arquivo = os.path.join(\"figuras\", \"exercicio_02_rede_circular.png\")\n",
        "        titulo = \"Rede de E-mails Direcionada (Circular Layout)\"\n",
        "    else:\n",
        "        print(\"Layout invÃ¡lido. Usando spring como padrÃ£o.\")\n",
        "        posicao = nx.spring_layout(grafo, k=0.15, iterations=20)\n",
        "        nome_arquivo = os.path.join(\"figuras\", \"exercicio_02_rede_spring.png\")\n",
        "        titulo = \"Rede de E-mails Direcionada (Spring Layout)\"\n",
        "\n",
        "    nx.draw(grafo, posicao, node_size=50, arrows=True, with_labels=False)\n",
        "    plt.title(titulo)\n",
        "    plt.savefig(nome_arquivo)\n",
        "    plt.close()\n",
        "    print(f\"VisualizaÃ§Ã£o da rede salva como '{nome_arquivo}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff9dc6c6",
      "metadata": {
        "id": "ff9dc6c6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "def exercicio_3(dados):\n",
        "    \"\"\"\n",
        "    Calcula a mÃ©dia dos menores caminhos na rede direcionada e analisa conectividade e eficiÃªncia.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "    Returns:\n",
        "        float: MÃ©dia dos menores caminhos (maior componente conexo ou grafo completo).\n",
        "    \"\"\"\n",
        "    # Usa grafo direcionado para refletir a rede de e-mails\n",
        "    grafo = nx.DiGraph()\n",
        "    arestas = dados[['origem', 'destino']].values\n",
        "    grafo.add_edges_from(arestas)\n",
        "\n",
        "    # Verifica se o grafo Ã© fortemente conectado (para DiGraph)\n",
        "    if nx.is_strongly_connected(grafo):\n",
        "        media_caminhos = nx.average_shortest_path_length(grafo)\n",
        "        print(f\"MÃ©dia dos menores caminhos (grafo completo): {media_caminhos:.4f}\")\n",
        "    else:\n",
        "        # Usa o maior componente fortemente conexo\n",
        "        maior_componente = max(nx.strongly_connected_components(grafo), key=len)\n",
        "        grafo_componente = grafo.subgraph(maior_componente).copy()\n",
        "        media_caminhos = nx.average_shortest_path_length(grafo_componente)\n",
        "        print(f\"MÃ©dia dos menores caminhos (maior componente fortemente conexo): {media_caminhos:.4f}\")\n",
        "\n",
        "    # InterpretaÃ§Ã£o detalhada\n",
        "    print(\"\\nAnÃ¡lise da conectividade e eficiÃªncia:\")\n",
        "    if media_caminhos < 6:\n",
        "        print(f\"A mÃ©dia de {media_caminhos:.4f} indica alta conectividade (caracterÃ­stica de mundo pequeno).\")\n",
        "        print(\"E-mails tendem a alcanÃ§ar destinatÃ¡rios com poucos intermediÃ¡rios, sugerindo comunicaÃ§Ã£o eficiente.\")\n",
        "    else:\n",
        "        print(f\"A mÃ©dia de {media_caminhos:.4f} sugere conectividade moderada a baixa.\")\n",
        "        print(\"A comunicaÃ§Ã£o pode ser menos eficiente, exigindo mais intermediÃ¡rios para e-mails entre nÃ³s distantes.\")\n",
        "    print(\"Em redes sociais, mÃ©dias abaixo de 6 sÃ£o comuns, como no conceito de 'seis graus de separaÃ§Ã£o'.\")\n",
        "\n",
        "    return media_caminhos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0d72921",
      "metadata": {
        "id": "e0d72921"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "def exercicio_4(dados):\n",
        "    \"\"\"\n",
        "    Calcula os top 5 nÃ³s com base em diferentes mÃ©tricas de centralidade.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "        metrica (str): 'betweenness', 'degree', ou 'closeness'.\n",
        "    Returns:\n",
        "        list: Lista de tuplas (nÃ³, valor) para os 5 principais nÃ³s.\n",
        "    \"\"\"\n",
        "    grafo = nx.DiGraph()\n",
        "    arestas = dados[['origem', 'destino']].values\n",
        "    grafo.add_edges_from(arestas)\n",
        "\n",
        "    centralidade = nx.betweenness_centrality(grafo)\n",
        "    nome_metrica = \"centralidade de intermediaÃ§Ã£o\"\n",
        "\n",
        "    top_5 = sorted(centralidade.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "    print(f\"Top 5 nÃ³s por {nome_metrica}:\")\n",
        "    for no, valor in top_5:\n",
        "        print(f\"NÃ³ {no}: {valor:.4f}\")\n",
        "        print(\"NÃ³s com alta intermediaÃ§Ã£o conectam grupos distintos.\")\n",
        "\n",
        "    print(\"\\nInterpretaÃ§Ã£o no contexto da instituiÃ§Ã£o de pesquisa:\")\n",
        "    print(\"A centralidade de intermediaÃ§Ã£o mede a frequÃªncia com que um nÃ³ aparece nos menores caminhos entre outros nÃ³s na rede de e-mails.\")\n",
        "    print(\"NÃ³s com alta centralidade sÃ£o cruciais para o fluxo de informaÃ§Ãµes, funcionando como pontes entre diferentes grupos ou departamentos.\")\n",
        "    print(\"\\nPossÃ­veis papÃ©is desses nÃ³s incluem:\")\n",
        "    print(\"- **LÃ­deres de pesquisa**: Conectam equipes interdisciplinares, promovendo colaboraÃ§Ã£o em projetos acadÃªmicos.\")\n",
        "    print(\"- **Administradores**: Coordenam comunicaÃ§Ãµes institucionais, como anÃºncios ou decisÃµes estratÃ©gicas.\")\n",
        "    print(\"- **Sistemas centrais**: Servidores de e-mail ou newsletters que disseminam informaÃ§Ãµes amplamente.\")\n",
        "    print(\"\\nEstrutura da rede de comunicaÃ§Ã£o:\")\n",
        "    print(\"A presenÃ§a de nÃ³s com alta centralidade sugere uma rede integrada, onde a colaboraÃ§Ã£o entre departamentos Ã© facilitada.\")\n",
        "    print(\"No entanto, a rede Ã© centralizada, dependendo de poucos nÃ³s crÃ­ticos. Isso implica:\")\n",
        "    print(\"- **EficiÃªncia**: InformaÃ§Ãµes fluem rapidamente atravÃ©s desses nÃ³s, agilizando a troca de conhecimento.\")\n",
        "    print(\"- **Vulnerabilidade**: A sobrecarga ou ausÃªncia desses nÃ³s pode fragmentar a comunicaÃ§Ã£o, isolando grupos e dificultando a colaboraÃ§Ã£o.\")\n",
        "    print(\"\\nImplicaÃ§Ãµes:\")\n",
        "    print(\"Esses nÃ³s sÃ£o pontos estratÃ©gicos para a instituiÃ§Ã£o, mas tambÃ©m pontos de risco. EstratÃ©gias como descentralizar comunicaÃ§Ãµes ou criar redundÃ¢ncias podem mitigar dependÃªncias.\")\n",
        "\n",
        "    return top_5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7edc7e7a",
      "metadata": {
        "id": "7edc7e7a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from networkx.algorithms.community import louvain_partitions\n",
        "\n",
        "def exercicio_5(dados):\n",
        "    \"\"\"\n",
        "    Detecta comunidades usando o algoritmo de Louvain do NetworkX e encontra o nÃ³ principal por maior grau de entrada.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "    Returns:\n",
        "        dict: DicionÃ¡rio mapeando ID da comunidade para o nÃ³ principal.\n",
        "    \"\"\"\n",
        "    # Cria o grafo direcionado\n",
        "    grafo = nx.DiGraph()\n",
        "    arestas = dados[['origem', 'destino']].values\n",
        "    grafo.add_edges_from(arestas)\n",
        "\n",
        "    # Converte para grafo nÃ£o direcionado para detecÃ§Ã£o de comunidades\n",
        "    grafo_nao_direcionado = grafo.to_undirected()\n",
        "\n",
        "    # Usa louvain_partitions para detectar comunidades\n",
        "    particoes = louvain_partitions(grafo_nao_direcionado, seed=42)  # seed para reprodutibilidade\n",
        "\n",
        "    # Seleciona a primeira partiÃ§Ã£o (ou a com maior modularidade, se necessÃ¡rio)\n",
        "    particao = next(particoes)  # Pega a primeira partiÃ§Ã£o\n",
        "\n",
        "    # Organiza nÃ³s por comunidade\n",
        "    comunidades = {}\n",
        "    for id_comunidade, comunidade in enumerate(particao):\n",
        "        comunidades[id_comunidade] = list(comunidade)\n",
        "\n",
        "    # Encontra o nÃ³ principal por maior grau de entrada em cada comunidade\n",
        "    nos_principais = {}\n",
        "    for id_comunidade, nos in comunidades.items():\n",
        "        graus = grafo.in_degree()\n",
        "        nome_criterio = \"maior grau de entrada\"\n",
        "        graus_comunidade = [(no, graus[no]) for no in nos if no in grafo.nodes()]\n",
        "        if graus_comunidade:  # Verifica se a comunidade nÃ£o estÃ¡ vazia\n",
        "            no_principal = max(graus_comunidade, key=lambda x: x[1])[0]\n",
        "            nos_principais[id_comunidade] = no_principal\n",
        "            print(f\"Comunidade {id_comunidade}: NÃ³ {no_principal} com {nome_criterio}\")\n",
        "        else:\n",
        "            print(f\"Comunidade {id_comunidade}: Nenhuma aresta de entrada encontrada\")\n",
        "\n",
        "    print(f\"NÃ³s selecionados por {nome_criterio} sÃ£o centrais em suas comunidades.\")\n",
        "    return nos_principais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "798b176d",
      "metadata": {
        "id": "798b176d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def exercicio_6(dados, nos_principais):\n",
        "    \"\"\"\n",
        "    Plota o nÃºmero de arestas de entrada ao longo de 803 dias para os nÃ³s principais.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "        nos_principais (dict): NÃ³s com maior grau de entrada por comunidade.\n",
        "    \"\"\"\n",
        "    dados['dia'] = dados['timestamp'] // (24 * 3600)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for id_comunidade, no in nos_principais.items():\n",
        "        arestas_no = dados[dados['destino'] == no]\n",
        "        contagem_diaria = arestas_no.groupby('dia').size()\n",
        "        contagem_diaria = contagem_diaria.reindex(range(803), fill_value=0)\n",
        "        plt.plot(contagem_diaria.index, contagem_diaria.values, label=f\"NÃ³ {no} (Comunidade {id_comunidade})\")\n",
        "\n",
        "    plt.xlabel(\"Dia\")\n",
        "    plt.ylabel(\"NÃºmero de E-mails Recebidos\")\n",
        "    plt.title(\"E-mails Recebidos ao Longo do Tempo\")\n",
        "    plt.legend()\n",
        "    nome_arquivo = os.path.join(\"figuras\", \"exercicio_06_temporal.png\")\n",
        "    plt.savefig(nome_arquivo)\n",
        "    plt.close()\n",
        "    print(f\"VisualizaÃ§Ã£o temporal salva como '{nome_arquivo}'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5c0bec9",
      "metadata": {
        "id": "d5c0bec9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "\n",
        "def exercicio_7(dados, nos_principais):\n",
        "    \"\"\"\n",
        "    DecompÃµe sÃ©ries temporais de dois nÃ³s escolhidos aleatoriamente, compara tendÃªncia e sazonalidade,\n",
        "    e retorna os nÃ³s para uso posterior.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede (origem, destino, timestamp).\n",
        "        nos_principais (dict): NÃ³s com maior grau de entrada por comunidade.\n",
        "    Returns:\n",
        "        tuple: (no_a, no_b), IDs dos nÃ³s selecionados.\n",
        "    \"\"\"\n",
        "    # Seleciona dois nÃ³s aleatoriamente\n",
        "    random.seed(42)  # Para reprodutibilidade\n",
        "    try:\n",
        "        nos = random.sample(list(nos_principais.values()), k=2)\n",
        "    except ValueError as e:\n",
        "        print(f\"Erro ao selecionar nÃ³s: {str(e)}. Usando nÃ³s padrÃ£o ou repetidos.\")\n",
        "        nos = list(nos_principais.values())[:2]\n",
        "        if len(nos) < 2:\n",
        "            nos = [nos[0], nos[0]] if nos else [0, 0]\n",
        "\n",
        "    no_a, no_b = nos\n",
        "    print(f\"NÃ³s selecionados: A={no_a}, B={no_b}\")\n",
        "\n",
        "    # Converte timestamps para dias\n",
        "    dados['dia'] = dados['timestamp'] // (24 * 3600)\n",
        "    max_dias = 803  # PerÃ­odo total da rede (fixo para consistÃªncia)\n",
        "\n",
        "    def obter_serie_temporal(no):\n",
        "        \"\"\"ObtÃ©m a sÃ©rie temporal de arestas de entrada para um nÃ³.\"\"\"\n",
        "        arestas_no = dados[dados['destino'] == no]\n",
        "        contagem_diaria = arestas_no.groupby('dia').size()\n",
        "        return contagem_diaria.reindex(range(max_dias), fill_value=0)\n",
        "\n",
        "    try:\n",
        "        # ObtÃ©m sÃ©ries temporais\n",
        "        serie_a = obter_serie_temporal(no_a)\n",
        "        serie_b = obter_serie_temporal(no_b)\n",
        "\n",
        "        # DecomposiÃ§Ã£o: modelo aditivo, perÃ­odo semanal\n",
        "        modelo = \"additive\"\n",
        "        periodo_sazonal = 7\n",
        "        decomp_a = seasonal_decompose(serie_a, model=modelo, period=periodo_sazonal, extrapolate_trend='freq')\n",
        "        decomp_b = seasonal_decompose(serie_b, model=modelo, period=periodo_sazonal, extrapolate_trend='freq')\n",
        "\n",
        "        # Gera visualizaÃ§Ãµes\n",
        "        for no, decomp in [(no_a, decomp_a), (no_b, decomp_b)]:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.subplot(411)\n",
        "            plt.plot(decomp.observed, label='Observado')\n",
        "            plt.legend(loc='best')\n",
        "            plt.subplot(412)\n",
        "            plt.plot(decomp.trend, label='TendÃªncia')\n",
        "            plt.legend(loc='best')\n",
        "            plt.subplot(413)\n",
        "            plt.plot(decomp.seasonal, label='Sazonalidade')\n",
        "            plt.legend(loc='best')\n",
        "            plt.subplot(414)\n",
        "            plt.plot(decomp.resid, label='RuÃ­do')\n",
        "            plt.legend(loc='best')\n",
        "            nome_arquivo = os.path.join(\"figuras\", f\"exercicio_07_no_{no}.png\")\n",
        "            plt.suptitle(f\"DecomposiÃ§Ã£o da SÃ©rie Temporal - NÃ³ {no} (PerÃ­odo Semanal, Modelo Aditivo)\")\n",
        "            plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "            plt.savefig(nome_arquivo)\n",
        "            plt.close()\n",
        "            print(f\"GrÃ¡fico salvo como '{nome_arquivo}'.\")\n",
        "\n",
        "        # Compara tendÃªncias e sazonalidades\n",
        "        correlacao_tendencia = np.corrcoef(decomp_a.trend, decomp_b.trend)[0, 1]\n",
        "        correlacao_sazonalidade = np.corrcoef(decomp_a.seasonal, decomp_b.seasonal)[0, 1]\n",
        "        print(f\"\\nCorrelaÃ§Ã£o entre nÃ³s A={no_a} e B={no_b}:\")\n",
        "        print(f\"  TendÃªncia: {correlacao_tendencia:.4f}\")\n",
        "        print(f\"  Sazonalidade: {correlacao_sazonalidade:.4f}\")\n",
        "\n",
        "        # ConclusÃµes interpretativas\n",
        "        print(\"\\nInterpretaÃ§Ã£o no contexto da instituiÃ§Ã£o:\")\n",
        "        if abs(correlacao_tendencia) > 0.7:\n",
        "            print(f\"A alta correlaÃ§Ã£o de tendÃªncia ({correlacao_tendencia:.4f}) indica que A e B tÃªm padrÃµes de longo prazo semelhantes. Eles podem ser lÃ­deres ou departamentos centrais com fluxos de e-mails sincronizados, como grupos de pesquisa colaborativos.\")\n",
        "        else:\n",
        "            print(f\"A baixa correlaÃ§Ã£o de tendÃªncia ({correlacao_tendencia:.4f}) sugere que A e B tÃªm dinÃ¢micas distintas. Eles podem representar Ã¡reas diferentes, como administraÃ§Ã£o e pesquisa, com demandas de comunicaÃ§Ã£o independentes.\")\n",
        "\n",
        "        if abs(correlacao_sazonalidade) > 0.7:\n",
        "            print(f\"A alta correlaÃ§Ã£o de sazonalidade ({correlacao_sazonalidade:.4f}) mostra que A e B seguem ciclos semanais similares, possivelmente devido a rotinas institucionais compartilhadas, como reuniÃµes ou relatÃ³rios.\")\n",
        "        else:\n",
        "            print(f\"A baixa correlaÃ§Ã£o de sazonalidade ({correlacao_sazonalidade:.4f}) indica ciclos distintos, talvez com um nÃ³ ativo em dias Ãºteis e outro com picos esporÃ¡dicos, refletindo funÃ§Ãµes variadas.\")\n",
        "\n",
        "        print(\"Esses padrÃµes sugerem estratÃ©gias para otimizar a comunicaÃ§Ã£o, como sincronizar fluxos para nÃ³s correlacionados ou diversificar canais para nÃ³s independentes.\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Erro na anÃ¡lise temporal: {str(e)}. NÃ£o foi possÃ­vel completar a decomposiÃ§Ã£o.\")\n",
        "        return None, None\n",
        "\n",
        "    return no_a, no_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "907a7f07",
      "metadata": {
        "id": "907a7f07"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def exercicio_8(dados, no_a, no_b):\n",
        "    \"\"\"\n",
        "    Cria nÃ³ C e redireciona aleatoriamente 25% das arestas de A e B para C.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame com as arestas da rede.\n",
        "        no_a (int): NÃ³ A selecionado no ExercÃ­cio 7.\n",
        "        no_b (int): NÃ³ B selecionado no ExercÃ­cio 7.\n",
        "    Returns:\n",
        "        tuple: DataFrame modificado e ID do novo nÃ³ C.\n",
        "    \"\"\"\n",
        "    print(f\"Usando nÃ³s do ExercÃ­cio 7: A={no_a}, B={no_b}\")\n",
        "\n",
        "    # Cria o novo nÃ³ C\n",
        "    novo_no = max(dados['origem'].max(), dados['destino'].max()) + 1\n",
        "    print(f\"Criando novo nÃ³ C: {novo_no}\")\n",
        "\n",
        "    # Cria uma cÃ³pia do DataFrame para modificaÃ§Ãµes\n",
        "    dados_modificados = dados.copy()\n",
        "\n",
        "    def redirecionar_arestas(no):\n",
        "        \"\"\"Redireciona aleatoriamente 25% das arestas destinadas ao nÃ³ para novo_no.\"\"\"\n",
        "        arestas_no = dados_modificados[dados_modificados['destino'] == no]\n",
        "        num_arestas = len(arestas_no)\n",
        "        num_redirecionar = int(0.25 * num_arestas)\n",
        "        if num_redirecionar == 0:\n",
        "            print(f\"Nenhuma aresta redirecionada para nÃ³ {no} (menos de 4 arestas).\")\n",
        "            return\n",
        "\n",
        "        # Seleciona aleatoriamente 25% das arestas\n",
        "        indices = arestas_no.sample(n=num_redirecionar, random_state=42).index\n",
        "        dados_modificados.loc[indices, 'destino'] = novo_no\n",
        "        print(f\"Redirecionadas {num_redirecionar} arestas do nÃ³ {no} por amostragem aleatÃ³ria.\")\n",
        "\n",
        "    # Redireciona arestas para A e B\n",
        "    redirecionar_arestas(no_a)\n",
        "    redirecionar_arestas(no_b)\n",
        "\n",
        "    return dados_modificados, novo_no"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3e4ec9b",
      "metadata": {
        "id": "b3e4ec9b"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def exercicio_9(dados_modificados, no_a, no_b, novo_no):\n",
        "    \"\"\"\n",
        "    Repete a decomposiÃ§Ã£o das sÃ©ries temporais para os nÃ³s A, B e C apÃ³s modificaÃ§Ã£o, compara tendÃªncias e sazonalidades, e tira conclusÃµes.\n",
        "    Args:\n",
        "        dados_modificados (pd.DataFrame): DataFrame com a rede modificada.\n",
        "        no_a (int): NÃ³ A do ExercÃ­cio 7.\n",
        "        no_b (int): NÃ³ B do ExercÃ­cio 7.\n",
        "        novo_no (int): ID do novo nÃ³ C do ExercÃ­cio 8.\n",
        "    \"\"\"\n",
        "    nos = [no_a, no_b, novo_no]\n",
        "    print(f\"NÃ³s analisados: A={no_a}, B={no_b}, C={novo_no}\")\n",
        "\n",
        "    # Converte timestamps para dias\n",
        "    dados_modificados['dia'] = dados_modificados['timestamp'] // (24 * 3600)\n",
        "\n",
        "    def obter_serie_temporal(no):\n",
        "        \"\"\"ObtÃ©m a sÃ©rie temporal de arestas de entrada para um nÃ³.\"\"\"\n",
        "        arestas_no = dados_modificados[dados_modificados['destino'] == no]\n",
        "        contagem_diaria = arestas_no.groupby('dia').size()\n",
        "        return contagem_diaria.reindex(range(803), fill_value=0)\n",
        "\n",
        "    try:\n",
        "        # ConfiguraÃ§Ã£o fixa: modelo aditivo, perÃ­odo 7 dias\n",
        "        modelo = \"additive\"\n",
        "        periodo = 7\n",
        "\n",
        "        # DecompÃµe as sÃ©ries temporais para A, B e C\n",
        "        series = {no: obter_serie_temporal(no) for no in nos}\n",
        "        decomps = {\n",
        "            no: seasonal_decompose(serie, model=modelo, period=periodo, extrapolate_trend='freq')\n",
        "            for no, serie in series.items()\n",
        "        }\n",
        "\n",
        "        # Gera visualizaÃ§Ãµes para cada nÃ³\n",
        "        for no in nos:\n",
        "            decomp = decomps[no]\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.subplot(411)\n",
        "            plt.plot(decomp.observed, label='Observado')\n",
        "            plt.legend()\n",
        "            plt.subplot(412)\n",
        "            plt.plot(decomp.trend, label='TendÃªncia')\n",
        "            plt.legend()\n",
        "            plt.subplot(413)\n",
        "            plt.plot(decomp.seasonal, label='Sazonalidade')\n",
        "            plt.legend()\n",
        "            plt.subplot(414)\n",
        "            plt.plot(decomp.resid, label='RuÃ­do')\n",
        "            plt.legend()\n",
        "            nome_arquivo = os.path.join(\"figuras\", f\"exercicio_09_no_{no}_modificado.png\")\n",
        "            plt.suptitle(f\"DecomposiÃ§Ã£o da SÃ©rie Temporal para NÃ³ {no} (Modificado, PerÃ­odo=7, Modelo=aditivo)\")\n",
        "            plt.savefig(nome_arquivo)\n",
        "            plt.close()\n",
        "            print(f\"DecomposiÃ§Ã£o salva como '{nome_arquivo}'.\")\n",
        "\n",
        "        # Compara tendÃªncias e sazonalidades (A vs. B, A vs. C, B vs. C)\n",
        "        pares = [(\"A vs. B\", no_a, no_b), (\"A vs. C\", no_a, novo_no), (\"B vs. C\", no_b, novo_no)]\n",
        "        for nome_par, n1, n2 in pares:\n",
        "            correlacao_tendencia = np.corrcoef(decomps[n1].trend, decomps[n2].trend)[0, 1]\n",
        "            correlacao_sazonalidade = np.corrcoef(decomps[n1].seasonal, decomps[n2].seasonal)[0, 1]\n",
        "            print(f\"\\nCorrelaÃ§Ãµes para {nome_par}:\")\n",
        "            print(f\"  TendÃªncia: {correlacao_tendencia:.4f}\")\n",
        "            print(f\"  Sazonalidade: {correlacao_sazonalidade:.4f}\")\n",
        "\n",
        "        # ConclusÃµes interpretativas\n",
        "        print(\"\\nInterpretaÃ§Ã£o dos resultados apÃ³s redirecionamento:\")\n",
        "        # A vs. B\n",
        "        correlacao_tendencia_ab = np.corrcoef(decomps[no_a].trend, decomps[no_b].trend)[0, 1]\n",
        "        correlacao_sazonalidade_ab = np.corrcoef(decomps[no_a].seasonal, decomps[no_b].seasonal)[0, 1]\n",
        "        if abs(correlacao_tendencia_ab) > 0.7:\n",
        "            print(f\"A alta correlaÃ§Ã£o da tendÃªncia entre A e B ({correlacao_tendencia_ab:.4f}) sugere que o redirecionamento para C nÃ£o alterou significativamente seus padrÃµes de longo prazo. Eles continuam desempenhando papÃ©is complementares.\")\n",
        "        else:\n",
        "            print(f\"A baixa correlaÃ§Ã£o da tendÃªncia entre A e B ({correlacao_tendencia_ab:.4f}) indica que o redirecionamento pode ter diferenciado ainda mais suas dinÃ¢micas de longo prazo, talvez reduzindo interdependÃªncias.\")\n",
        "\n",
        "        if abs(correlacao_sazonalidade_ab) > 0.7:\n",
        "            print(f\"A alta correlaÃ§Ã£o da sazonalidade entre A e B ({correlacao_sazonalidade_ab:.4f}) implica que os ciclos semanais permanecem sincronizados, apesar do redirecionamento para C.\")\n",
        "        else:\n",
        "            print(f\"A baixa correlaÃ§Ã£o da sazonalidade entre A e B ({correlacao_sazonalidade_ab:.4f}) sugere que o redirecionamento alterou os ciclos temporais, possivelmente redistribuindo picos de e-mails.\")\n",
        "\n",
        "        # Impacto em C\n",
        "        correlacao_tendencia_ac = np.corrcoef(decomps[no_a].trend, decomps[novo_no].trend)[0, 1]\n",
        "        correlacao_tendencia_bc = np.corrcoef(decomps[no_b].trend, decomps[novo_no].trend)[0, 1]\n",
        "        correlacao_sazonalidade_ac = np.corrcoef(decomps[no_a].seasonal, decomps[novo_no].seasonal)[0, 1]\n",
        "        correlacao_sazonalidade_bc = np.corrcoef(decomps[no_b].seasonal, decomps[novo_no].seasonal)[0, 1]\n",
        "\n",
        "        if abs(correlacao_tendencia_ac) > 0.7 or abs(correlacao_tendencia_bc) > 0.7:\n",
        "            print(f\"A tendÃªncia de C Ã© semelhante Ã  de A ({correlacao_tendencia_ac:.4f}) ou B ({correlacao_tendencia_bc:.4f}), indicando que C assumiu parte do papel de longo prazo de um dos nÃ³s originais.\")\n",
        "        else:\n",
        "            print(f\"A tendÃªncia de C Ã© distinta de A ({correlacao_tendencia_ac:.4f}) e B ({correlacao_tendencia_bc:.4f}), sugerindo que C opera de forma independente em longo prazo.\")\n",
        "\n",
        "        if abs(correlacao_sazonalidade_ac) > 0.7 or abs(correlacao_sazonalidade_bc) > 0.7:\n",
        "            print(f\"A sazonalidade de C Ã© semelhante Ã  de A ({correlacao_sazonalidade_ac:.4f}) ou B ({correlacao_sazonalidade_bc:.4f}), mostrando que C herdou ciclos semanais de pelo menos um dos nÃ³s.\")\n",
        "        else:\n",
        "            print(f\"A sazonalidade de C Ã© distinta de A ({correlacao_sazonalidade_ac:.4f}) e B ({correlacao_sazonalidade_bc:.4f}), indicando que C tem padrÃµes cÃ­clicos prÃ³prios.\")\n",
        "\n",
        "        print(\"O redirecionamento para C pode ter redistribuÃ­do a carga de comunicaÃ§Ã£o, afetando estratÃ©gias institucionais, como balanceamento de servidores ou fluxos de e-mails.\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Erro na decomposiÃ§Ã£o: {str(e)}. NÃ£o foi possÃ­vel completar a anÃ¡lise.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d617f2",
      "metadata": {
        "id": "e6d617f2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "def exercicio_10(dados, dados_modificados, no_a, no_b, novo_no, teste=\"t_test\"):\n",
        "    \"\"\"\n",
        "    Analisa mudanÃ§as no fluxo de e-mails para A, B e C com testes estatÃ­sticos.\n",
        "    Args:\n",
        "        dados (pd.DataFrame): DataFrame original.\n",
        "        dados_modificados (pd.DataFrame): DataFrame com a rede modificada.\n",
        "        no_a (int): NÃ³ A do ExercÃ­cio 7.\n",
        "        no_b (int): NÃ³ B do ExercÃ­cio 7.\n",
        "        novo_no (int): ID do novo nÃ³ C do ExercÃ­cio 8.\n",
        "        teste (str): 't_test' ou 'mann_whitney'.\n",
        "    \"\"\"\n",
        "    print(f\"Analisando nÃ³s: A={no_a}, B={no_b}, C={novo_no}\")\n",
        "\n",
        "    # Calcula grau de entrada total\n",
        "    grau_entrada_antes = dados.groupby('destino').size()\n",
        "    grau_entrada_depois = dados_modificados.groupby('destino').size()\n",
        "\n",
        "    def obter_grau_entrada(no):\n",
        "        return grau_entrada_antes.get(no, 0), grau_entrada_depois.get(no, 0)\n",
        "\n",
        "    grau_a_antes, grau_a_depois = obter_grau_entrada(no_a)\n",
        "    grau_b_antes, grau_b_depois = obter_grau_entrada(no_b)\n",
        "    grau_c_antes, grau_c_depois = obter_grau_entrada(novo_no)\n",
        "\n",
        "    print(f\"NÃ³ A grau de entrada: Antes={grau_a_antes}, Depois={grau_a_depois}\")\n",
        "    print(f\"NÃ³ B grau de entrada: Antes={grau_b_antes}, Depois={grau_b_depois}\")\n",
        "    print(f\"NÃ³ C grau de entrada: Antes={grau_c_antes}, Depois={grau_c_depois}\")\n",
        "\n",
        "    # Verifica reduÃ§Ã£o em A e B, aumento em C\n",
        "    reduziu_a = grau_a_depois < grau_a_antes\n",
        "    reduziu_b = grau_b_depois < grau_b_antes\n",
        "    aumentou_c = grau_c_depois > grau_c_antes\n",
        "    if reduziu_a and reduziu_b:\n",
        "        print(\"O fluxo de e-mails para A e B diminuiu apÃ³s introduÃ§Ã£o do nÃ³ C.\")\n",
        "        if aumentou_c:\n",
        "            print(\"O nÃ³ C absorveu parte do fluxo, como esperado.\")\n",
        "        else:\n",
        "            print(\"O nÃ³ C nÃ£o registrou aumento correspondente, sugerindo possÃ­veis discrepÃ¢ncias.\")\n",
        "    else:\n",
        "        print(\"O fluxo de e-mails para A e/ou B nÃ£o diminuiu consistentemente.\")\n",
        "\n",
        "    # SÃ©ries temporais diÃ¡rias\n",
        "    dados['dia'] = dados['timestamp'] // (24 * 3600)\n",
        "    dados_modificados['dia'] = dados_modificados['timestamp'] // (24 * 3600)\n",
        "\n",
        "    def obter_grau_entrada_diario(no, df):\n",
        "        arestas_no = df[df['destino'] == no]\n",
        "        return arestas_no.groupby('dia').size().reindex(range(803), fill_value=0)\n",
        "\n",
        "    # Gera sÃ©ries para A, B e C\n",
        "    nos = [(no_a, \"A\"), (no_b, \"B\"), (novo_no, \"C\")]\n",
        "    series = {\n",
        "        nome: {\n",
        "            \"antes\": obter_grau_entrada_diario(no, dados),\n",
        "            \"depois\": obter_grau_entrada_diario(no, dados_modificados)\n",
        "        }\n",
        "        for no, nome in nos\n",
        "    }\n",
        "\n",
        "    # Testes de hipÃ³teses\n",
        "    alfa = 0.05\n",
        "    for no, nome in nos:\n",
        "        serie_antes = series[nome][\"antes\"]\n",
        "        serie_depois = series[nome][\"depois\"]\n",
        "        try:\n",
        "            if teste == \"t_test\":\n",
        "                estatistica, valor_p = stats.ttest_rel(serie_antes, serie_depois)\n",
        "                nome_teste = \"teste t pareado\"\n",
        "            elif teste == \"mann_whitney\":\n",
        "                estatistica, valor_p = stats.mannwhitneyu(serie_antes, serie_depois, alternative='two-sided')\n",
        "                nome_teste = \"teste de Mann-Whitney U\"\n",
        "            else:\n",
        "                print(\"Teste invÃ¡lido. Usando t_test.\")\n",
        "                estatistica, valor_p = stats.ttest_rel(serie_antes, serie_depois)\n",
        "                nome_teste = \"teste t pareado\"\n",
        "\n",
        "            print(f\"NÃ³ {nome} ({no}) {nome_teste}: estatÃ­stica={estatistica:.4f}, p-valor={valor_p:.4f}\")\n",
        "            if valor_p < alfa:\n",
        "                print(f\"MudanÃ§a significativa no fluxo de e-mails do nÃ³ {nome} (p < {alfa}).\")\n",
        "            else:\n",
        "                print(f\"Sem mudanÃ§a significativa no fluxo de e-mails do nÃ³ {nome} (p >= {alfa}).\")\n",
        "\n",
        "        except ValueError as e:\n",
        "            print(f\"Erro no teste para nÃ³ {nome}: {str(e)}. Pulando anÃ¡lise estatÃ­stica.\")\n",
        "\n",
        "    # ConclusÃµes institucionais\n",
        "    print(\"\\nConclusÃµes para a instituiÃ§Ã£o:\")\n",
        "    if reduziu_a and reduziu_b and aumentou_c:\n",
        "        print(\"O redirecionamento para o nÃ³ C foi eficaz em reduzir a carga de e-mails em A e B, transferindo parte do fluxo para C. Isso pode aliviar servidores ou administradores sobrecarregados, melhorando a eficiÃªncia da comunicaÃ§Ã£o.\")\n",
        "        if series[\"A\"][\"depois\"].mean() < series[\"A\"][\"antes\"].mean() and series[\"B\"][\"depois\"].mean() < series[\"B\"][\"antes\"].mean():\n",
        "            print(\"Testes confirmam reduÃ§Ã£o significativa no fluxo diÃ¡rio, sugerindo que C assumiu responsabilidades de comunicaÃ§Ã£o.\")\n",
        "        else:\n",
        "            print(\"Embora o fluxo total tenha diminuÃ­do, os padrÃµes diÃ¡rios nÃ£o mudaram significativamente, indicando que a reduÃ§Ã£o pode ser distribuÃ­da irregularmente.\")\n",
        "    else:\n",
        "        print(\"O redirecionamento nÃ£o reduziu consistentemente o fluxo para A e B, ou C nÃ£o absorveu o fluxo esperado. Isso pode indicar que a intervenÃ§Ã£o nÃ£o foi suficiente para balancear a comunicaÃ§Ã£o.\")\n",
        "        print(\"Recomenda-se revisar a proporÃ§Ã£o de redirecionamento (25%) ou considerar outros nÃ³s para redistribuiÃ§Ã£o.\")\n",
        "\n",
        "    print(\"Esses resultados podem orientar ajustes na infraestrutura de e-mails, como adicionar mais nÃ³s ou otimizar fluxos para evitar gargalos.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc49eb7d",
      "metadata": {
        "id": "fc49eb7d"
      },
      "source": [
        "## ðŸš€ ExecuÃ§Ã£o AutomÃ¡tica dos ExercÃ­cios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa118d82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa118d82",
        "outputId": "797645d4-6f5c-426c-bbec-2f44f18a5b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ExercÃ­cio 1: Carregando dados...\n",
            "Dados convertidos e salvos como: email-Eu-core-temporal.csv\n",
            "Dataset carregado com 332334 arestas.\n",
            "\n",
            "ExercÃ­cio 2: Visualizando rede...\n",
            "VisualizaÃ§Ã£o da rede salva como 'figuras/exercicio_02_rede_spring.png'.\n",
            "\n",
            "ExercÃ­cio 3: Analisando mÃ©dia dos menores caminhos...\n",
            "MÃ©dia dos menores caminhos (maior componente fortemente conexo): 2.5475\n",
            "\n",
            "AnÃ¡lise da conectividade e eficiÃªncia:\n",
            "A mÃ©dia de 2.5475 indica alta conectividade (caracterÃ­stica de mundo pequeno).\n",
            "E-mails tendem a alcanÃ§ar destinatÃ¡rios com poucos intermediÃ¡rios, sugerindo comunicaÃ§Ã£o eficiente.\n",
            "Em redes sociais, mÃ©dias abaixo de 6 sÃ£o comuns, como no conceito de 'seis graus de separaÃ§Ã£o'.\n",
            "\n",
            "ExercÃ­cio 4: Calculando centralidade de intermediaÃ§Ã£o...\n",
            "Top 5 nÃ³s por centralidade de intermediaÃ§Ã£o:\n",
            "NÃ³ 90: 0.0749\n",
            "NÃ³s com alta intermediaÃ§Ã£o conectam grupos distintos.\n",
            "NÃ³ 951: 0.0389\n",
            "NÃ³s com alta intermediaÃ§Ã£o conectam grupos distintos.\n",
            "NÃ³ 2: 0.0280\n",
            "NÃ³s com alta intermediaÃ§Ã£o conectam grupos distintos.\n",
            "NÃ³ 120: 0.0255\n",
            "NÃ³s com alta intermediaÃ§Ã£o conectam grupos distintos.\n",
            "NÃ³ 159: 0.0255\n",
            "NÃ³s com alta intermediaÃ§Ã£o conectam grupos distintos.\n",
            "\n",
            "InterpretaÃ§Ã£o no contexto da instituiÃ§Ã£o de pesquisa:\n",
            "A centralidade de intermediaÃ§Ã£o mede a frequÃªncia com que um nÃ³ aparece nos menores caminhos entre outros nÃ³s na rede de e-mails.\n",
            "NÃ³s com alta centralidade sÃ£o cruciais para o fluxo de informaÃ§Ãµes, funcionando como pontes entre diferentes grupos ou departamentos.\n",
            "\n",
            "PossÃ­veis papÃ©is desses nÃ³s incluem:\n",
            "- **LÃ­deres de pesquisa**: Conectam equipes interdisciplinares, promovendo colaboraÃ§Ã£o em projetos acadÃªmicos.\n",
            "- **Administradores**: Coordenam comunicaÃ§Ãµes institucionais, como anÃºncios ou decisÃµes estratÃ©gicas.\n",
            "- **Sistemas centrais**: Servidores de e-mail ou newsletters que disseminam informaÃ§Ãµes amplamente.\n",
            "\n",
            "Estrutura da rede de comunicaÃ§Ã£o:\n",
            "A presenÃ§a de nÃ³s com alta centralidade sugere uma rede integrada, onde a colaboraÃ§Ã£o entre departamentos Ã© facilitada.\n",
            "No entanto, a rede Ã© centralizada, dependendo de poucos nÃ³s crÃ­ticos. Isso implica:\n",
            "- **EficiÃªncia**: InformaÃ§Ãµes fluem rapidamente atravÃ©s desses nÃ³s, agilizando a troca de conhecimento.\n",
            "- **Vulnerabilidade**: A sobrecarga ou ausÃªncia desses nÃ³s pode fragmentar a comunicaÃ§Ã£o, isolando grupos e dificultando a colaboraÃ§Ã£o.\n",
            "\n",
            "ImplicaÃ§Ãµes:\n",
            "Esses nÃ³s sÃ£o pontos estratÃ©gicos para a instituiÃ§Ã£o, mas tambÃ©m pontos de risco. EstratÃ©gias como descentralizar comunicaÃ§Ãµes ou criar redundÃ¢ncias podem mitigar dependÃªncias.\n",
            "\n",
            "ExercÃ­cio 5: Detectando comunidades...\n",
            "Comunidade 0: NÃ³ 534 com maior grau de entrada\n",
            "Comunidade 1: NÃ³ 450 com maior grau de entrada\n",
            "Comunidade 2: NÃ³ 383 com maior grau de entrada\n",
            "Comunidade 3: NÃ³ 506 com maior grau de entrada\n",
            "Comunidade 4: NÃ³ 897 com maior grau de entrada\n",
            "Comunidade 5: NÃ³ 238 com maior grau de entrada\n",
            "Comunidade 6: NÃ³ 629 com maior grau de entrada\n",
            "Comunidade 7: NÃ³ 90 com maior grau de entrada\n",
            "Comunidade 8: NÃ³ 742 com maior grau de entrada\n",
            "Comunidade 9: NÃ³ 540 com maior grau de entrada\n",
            "Comunidade 10: NÃ³ 115 com maior grau de entrada\n",
            "Comunidade 11: NÃ³ 951 com maior grau de entrada\n",
            "Comunidade 12: NÃ³ 577 com maior grau de entrada\n",
            "Comunidade 13: NÃ³ 159 com maior grau de entrada\n",
            "Comunidade 14: NÃ³ 61 com maior grau de entrada\n",
            "Comunidade 15: NÃ³ 915 com maior grau de entrada\n",
            "Comunidade 16: NÃ³ 2 com maior grau de entrada\n",
            "Comunidade 17: NÃ³ 502 com maior grau de entrada\n",
            "NÃ³s selecionados por maior grau de entrada sÃ£o centrais em suas comunidades.\n",
            "\n",
            "ExercÃ­cio 6: Visualizando comportamento temporal...\n",
            "VisualizaÃ§Ã£o temporal salva como 'figuras/exercicio_06_temporal.png'.\n",
            "\n",
            "ExercÃ­cio 7: Decompondo sÃ©ries temporais...\n",
            "NÃ³s selecionados: A=506, B=534\n",
            "GrÃ¡fico salvo como 'figuras/exercicio_07_no_506.png'.\n",
            "GrÃ¡fico salvo como 'figuras/exercicio_07_no_534.png'.\n",
            "\n",
            "CorrelaÃ§Ã£o entre nÃ³s A=506 e B=534:\n",
            "  TendÃªncia: 0.6138\n",
            "  Sazonalidade: 0.9738\n",
            "\n",
            "InterpretaÃ§Ã£o no contexto da instituiÃ§Ã£o:\n",
            "A baixa correlaÃ§Ã£o de tendÃªncia (0.6138) sugere que A e B tÃªm dinÃ¢micas distintas. Eles podem representar Ã¡reas diferentes, como administraÃ§Ã£o e pesquisa, com demandas de comunicaÃ§Ã£o independentes.\n",
            "A alta correlaÃ§Ã£o de sazonalidade (0.9738) mostra que A e B seguem ciclos semanais similares, possivelmente devido a rotinas institucionais compartilhadas, como reuniÃµes ou relatÃ³rios.\n",
            "Esses padrÃµes sugerem estratÃ©gias para otimizar a comunicaÃ§Ã£o, como sincronizar fluxos para nÃ³s correlacionados ou diversificar canais para nÃ³s independentes.\n",
            "\n",
            "ExercÃ­cio 8: Modificando a rede...\n",
            "Usando nÃ³s do ExercÃ­cio 7: A=506, B=534\n",
            "Criando novo nÃ³ C: 1005\n",
            "Redirecionadas 431 arestas do nÃ³ 506 por amostragem aleatÃ³ria.\n",
            "Redirecionadas 239 arestas do nÃ³ 534 por amostragem aleatÃ³ria.\n",
            "\n",
            "ExercÃ­cio 9: Decompondo sÃ©ries apÃ³s modificaÃ§Ã£o...\n",
            "NÃ³s analisados: A=506, B=534, C=1005\n",
            "DecomposiÃ§Ã£o salva como 'figuras/exercicio_09_no_506_modificado.png'.\n",
            "DecomposiÃ§Ã£o salva como 'figuras/exercicio_09_no_534_modificado.png'.\n",
            "DecomposiÃ§Ã£o salva como 'figuras/exercicio_09_no_1005_modificado.png'.\n",
            "\n",
            "CorrelaÃ§Ãµes para A vs. B:\n",
            "  TendÃªncia: 0.5823\n",
            "  Sazonalidade: 0.9777\n",
            "\n",
            "CorrelaÃ§Ãµes para A vs. C:\n",
            "  TendÃªncia: 0.8172\n",
            "  Sazonalidade: 0.9602\n",
            "\n",
            "CorrelaÃ§Ãµes para B vs. C:\n",
            "  TendÃªncia: 0.7263\n",
            "  Sazonalidade: 0.9457\n",
            "\n",
            "InterpretaÃ§Ã£o dos resultados apÃ³s redirecionamento:\n",
            "A baixa correlaÃ§Ã£o da tendÃªncia entre A e B (0.5823) indica que o redirecionamento pode ter diferenciado ainda mais suas dinÃ¢micas de longo prazo, talvez reduzindo interdependÃªncias.\n",
            "A alta correlaÃ§Ã£o da sazonalidade entre A e B (0.9777) implica que os ciclos semanais permanecem sincronizados, apesar do redirecionamento para C.\n",
            "A tendÃªncia de C Ã© semelhante Ã  de A (0.8172) ou B (0.7263), indicando que C assumiu parte do papel de longo prazo de um dos nÃ³s originais.\n",
            "A sazonalidade de C Ã© semelhante Ã  de A (0.9602) ou B (0.9457), mostrando que C herdou ciclos semanais de pelo menos um dos nÃ³s.\n",
            "O redirecionamento para C pode ter redistribuÃ­do a carga de comunicaÃ§Ã£o, afetando estratÃ©gias institucionais, como balanceamento de servidores ou fluxos de e-mails.\n",
            "\n",
            "ExercÃ­cio 10: Analisando impacto estatÃ­stico da mudanÃ§a...\n",
            "Analisando nÃ³s: A=506, B=534, C=1005\n",
            "NÃ³ A grau de entrada: Antes=1725, Depois=1294\n",
            "NÃ³ B grau de entrada: Antes=959, Depois=720\n",
            "NÃ³ C grau de entrada: Antes=0, Depois=670\n",
            "O fluxo de e-mails para A e B diminuiu apÃ³s introduÃ§Ã£o do nÃ³ C.\n",
            "O nÃ³ C absorveu parte do fluxo, como esperado.\n",
            "NÃ³ A (506) teste t pareado: estatÃ­stica=15.1002, p-valor=0.0000\n",
            "MudanÃ§a significativa no fluxo de e-mails do nÃ³ A (p < 0.05).\n",
            "NÃ³ B (534) teste t pareado: estatÃ­stica=12.3529, p-valor=0.0000\n",
            "MudanÃ§a significativa no fluxo de e-mails do nÃ³ B (p < 0.05).\n",
            "NÃ³ C (1005) teste t pareado: estatÃ­stica=-17.2371, p-valor=0.0000\n",
            "MudanÃ§a significativa no fluxo de e-mails do nÃ³ C (p < 0.05).\n",
            "\n",
            "ConclusÃµes para a instituiÃ§Ã£o:\n",
            "O redirecionamento para o nÃ³ C foi eficaz em reduzir a carga de e-mails em A e B, transferindo parte do fluxo para C. Isso pode aliviar servidores ou administradores sobrecarregados, melhorando a eficiÃªncia da comunicaÃ§Ã£o.\n",
            "Testes confirmam reduÃ§Ã£o significativa no fluxo diÃ¡rio, sugerindo que C assumiu responsabilidades de comunicaÃ§Ã£o.\n",
            "Esses resultados podem orientar ajustes na infraestrutura de e-mails, como adicionar mais nÃ³s ou otimizar fluxos para evitar gargalos.\n"
          ]
        }
      ],
      "source": [
        "# Cria a pasta 'figuras' se nÃ£o existir\n",
        "os.makedirs(\"figuras\", exist_ok=True)\n",
        "\n",
        "# ExercÃ­cio 1 - Carregamento\n",
        "print(\"ExercÃ­cio 1: Carregando dados...\")\n",
        "dados = carregar_dados(\"email-Eu-core-temporal.txt.gz\")\n",
        "\n",
        "# ExercÃ­cio 2 - VisualizaÃ§Ã£o\n",
        "print(\"\\nExercÃ­cio 2: Visualizando rede...\")\n",
        "exercicio_2(dados)\n",
        "\n",
        "# ExercÃ­cio 3 - AnÃ¡lise global\n",
        "print(\"\\nExercÃ­cio 3: Analisando mÃ©dia dos menores caminhos...\")\n",
        "exercicio_3(dados)\n",
        "\n",
        "# ExercÃ­cio 4 - AnÃ¡lise estrutural\n",
        "print(\"\\nExercÃ­cio 4: Calculando centralidade de intermediaÃ§Ã£o...\")\n",
        "exercicio_4(dados)\n",
        "\n",
        "# ExercÃ­cio 5 - Comunidades\n",
        "print(\"\\nExercÃ­cio 5: Detectando comunidades...\")\n",
        "nos_principais = exercicio_5(dados)\n",
        "\n",
        "# ExercÃ­cio 6 - AnÃ¡lise temporal\n",
        "print(\"\\nExercÃ­cio 6: Visualizando comportamento temporal...\")\n",
        "exercicio_6(dados, nos_principais)\n",
        "\n",
        "# ExercÃ­cio 7 - SÃ©ries temporais\n",
        "print(\"\\nExercÃ­cio 7: Decompondo sÃ©ries temporais...\")\n",
        "no_a, no_b = exercicio_7(dados, nos_principais)\n",
        "\n",
        "# ExercÃ­cio 8 - ModificaÃ§Ã£o da rede\n",
        "print(\"\\nExercÃ­cio 8: Modificando a rede...\")\n",
        "dados_modificados, novo_no = exercicio_8(dados, no_a, no_b)\n",
        "\n",
        "# ExercÃ­cio 9 - AnÃ¡lise da rede modificada\n",
        "print(\"\\nExercÃ­cio 9: Decompondo sÃ©ries apÃ³s modificaÃ§Ã£o...\")\n",
        "exercicio_9(dados_modificados, no_a, no_b, novo_no)\n",
        "\n",
        "# ExercÃ­cio 10 - Teste de hipÃ³teses\n",
        "print(\"\\nExercÃ­cio 10: Analisando impacto estatÃ­stico da mudanÃ§a...\")\n",
        "exercicio_10(dados, dados_modificados, no_a, no_b, novo_no, teste=\"t_test\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}